{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yangyo/anaconda3/envs/DL/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import sys\n",
    "from torchinfo import summary\n",
    "from ptflops import get_model_complexity_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_epochs = 10\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation and normalization\n",
    "transform_train = transforms.Compose([\n",
    "                    transforms.Resize((128, 128)),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "                    transforms.Resize((128, 128)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "# for 1 channel images\n",
    "transform_train1 = transforms.Compose([\n",
    "                    transforms.Resize((128, 128)),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "transform_test1 = transforms.Compose([\n",
    "                    transforms.Resize((128, 128)),\n",
    "                    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set length:63325, Validating Set length:450\n"
     ]
    }
   ],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, txt_file, img_dir, transform=None, convert = \"RGB\"):\n",
    "        self.img_labels = []\n",
    "        self.img_paths = []\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.convert = convert\n",
    "\n",
    "        with open(txt_file, 'r') as f:\n",
    "            for line in f:\n",
    "                path, label = line.strip().split(\" \")\n",
    "                self.img_paths.append(path)\n",
    "                self.img_labels.append(int(label))\n",
    "                #print(f\"{path} , {label}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_paths[idx])\n",
    "        image = Image.open(img_path).convert(self.convert)\n",
    "        label = self.img_labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "img_dir = os.getcwd() + \"/\"\n",
    "train_data = CustomImageDataset(txt_file=\"train.txt\", img_dir=img_dir, transform=transform_train)\n",
    "val_data = CustomImageDataset(txt_file=\"val.txt\", img_dir=img_dir, transform=transform_train)\n",
    "test_data = CustomImageDataset(txt_file=\"test.txt\", img_dir=img_dir, transform=transform_test)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Training Set length:{len(train_data)}, Validating Set length:{len(val_data)}\")\n",
    "\n",
    "test_num = len(test_data)\n",
    "test_steps = len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dynamic Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class attention2d(nn.Module):\n",
    "    def __init__(self,in_planes,ratio,K,temprature=30,init_weight=True):\n",
    "        super().__init__()\n",
    "        self.avgpool=nn.AdaptiveAvgPool2d(1)\n",
    "        self.temprature=temprature\n",
    "        out_channels = in_planes//ratio\n",
    "        self.cal = nn.Sequential(\n",
    "            nn.Conv2d(in_planes,out_channels,kernel_size=1,bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels,K,kernel_size=1,bias=False)\n",
    "        )\n",
    " \n",
    "        if(init_weight):\n",
    "            self._initialize_weights()\n",
    " \n",
    "    def update_temprature(self):\n",
    "        if(self.temprature>1):\n",
    "            self.temprature-=1\n",
    " \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            if isinstance(m ,nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    " \n",
    "    def forward(self,x):\n",
    "        att=self.avgpool(x) #bs,dim,1,1\n",
    "        att=self.cal(att).view(x.shape[0],-1) #bs,K\n",
    "        return F.softmax(att/self.temprature,-1)\n",
    " \n",
    "class DynamicConv(nn.Module):\n",
    "    def __init__(self,in_planes,out_planes,kernel_size,stride,padding=0,dilation=1,grounps=1,bias=True,K=4,temprature=30,ratio=1,init_weight=True):\n",
    "        super().__init__()\n",
    "        self.in_planes = in_planes\n",
    "        self.out_planes=out_planes\n",
    "        self.kernel_size=kernel_size\n",
    "        self.stride=stride\n",
    "        self.padding=padding\n",
    "        self.dilation=dilation\n",
    "        self.groups=grounps\n",
    "        self.bias=bias\n",
    "        self.K=K\n",
    "        self.init_weight=init_weight\n",
    "        self.attention=attention2d(in_planes = in_planes,ratio=ratio,K=K,temprature=temprature,init_weight=init_weight)\n",
    " \n",
    "        self.weight=nn.Parameter(torch.randn(K,out_planes,in_planes//grounps,kernel_size,kernel_size),requires_grad=True)\n",
    "        if(bias):\n",
    "            self.bias=nn.Parameter(torch.randn(K,out_planes),requires_grad=True)\n",
    "        else:\n",
    "            self.bias=None\n",
    "        \n",
    "        if(self.init_weight):\n",
    "            self._initialize_weights()\n",
    " \n",
    "        #TODO 初始化\n",
    "    def _initialize_weights(self):\n",
    "        for i in range(self.K):\n",
    "            nn.init.kaiming_uniform_(self.weight[i])\n",
    " \n",
    "    def forward(self,x):\n",
    "        bs,in_planels,h,w=x.shape\n",
    "        softmax_att=self.attention(x) #bs,K\n",
    "        x=x.view(1,-1,h,w)\n",
    "        weight=self.weight.view(self.K,-1) #K,-1\n",
    "        aggregate_weight=torch.mm(softmax_att,weight).view(bs*self.out_planes,self.in_planes//self.groups,self.kernel_size,self.kernel_size) #bs*out_p,in_p,k,k\n",
    " \n",
    "        if(self.bias is not None):\n",
    "            bias=self.bias.view(self.K,-1) #K,out_p\n",
    "            aggregate_bias=torch.mm(softmax_att,bias).view(-1) #bs,out_p\n",
    "            output=F.conv2d(x,weight=aggregate_weight,bias=aggregate_bias,stride=self.stride,padding=self.padding,groups=self.groups*bs,dilation=self.dilation)\n",
    "        else:\n",
    "            output=F.conv2d(x,weight=aggregate_weight,bias=None,stride=self.stride,padding=self.padding,groups=self.groups*bs,dilation=self.dilation)\n",
    "        \n",
    "        output=output.view(bs,self.out_planes,h,w)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Resnet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channel, out_channel, stride=1, downsample=None, **kwargs):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
    "        self.downsample = downsample\n",
    "        #self.drop = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        #out = self.drop(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, blocks_num, num_classes=1000, channels=3):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channel = 64\n",
    "        self.channels = channels\n",
    "        self.conv1 = nn.Conv2d(self.channels, self.in_channel, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_channel)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, blocks_num[0])\n",
    "        self.layer2 = self._make_layer(block, 128, blocks_num[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, blocks_num[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, blocks_num[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "    def _make_layer(self, block, channel, block_num, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channel != channel * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channel, channel * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(channel * block.expansion))\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channel, channel, downsample=downsample, stride=stride))\n",
    "        self.in_channel = channel * block.expansion\n",
    "\n",
    "        for _ in range(1, block_num):\n",
    "            layers.append(block(self.in_channel, channel))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "    \n",
    "        feature1 = self.layer1(x)\n",
    "        feature2 = self.layer2(feature1)\n",
    "        feature3 = self.layer3(feature2)\n",
    "        feature4 = self.layer4(feature3)\n",
    "    \n",
    "        x = self.avgpool(feature4)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        x = self.softmax(x)\n",
    "        return x, [feature1, feature2, feature3, feature4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Resnet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicBasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channel, out_channel, stride=1,dynamic = False, downsample=None, **kwargs):\n",
    "        super(DynamicBasicBlock, self).__init__()\n",
    "        if dynamic:\n",
    "            self.conv1 = DynamicConv(in_planes=in_channel, out_planes=out_channel, kernel_size=3, stride=stride, padding=1)\n",
    "            self.conv2 = DynamicConv(in_planes=out_channel, out_planes=out_channel, kernel_size=3, stride=1, padding=1)\n",
    "        else:\n",
    "            self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel, kernel_size=3, stride=stride, padding=1)\n",
    "            self.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
    "        self.downsample = downsample\n",
    "        #self.drop = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        #out = self.drop(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "class DynamicResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, blocks_num, num_classes=1000, channels=3):\n",
    "        super(DynamicResNet, self).__init__()\n",
    "        self.in_channel = 64\n",
    "        self.channels = channels\n",
    "\n",
    "        self.conv1 = DynamicConv(self.channels, self.in_channel, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_channel)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, blocks_num[0], dynamic=True)\n",
    "        self.layer2 = self._make_layer(block, 128, blocks_num[1], stride=2, dynamic=False)\n",
    "        self.layer3 = self._make_layer(block, 256, blocks_num[2], stride=2, dynamic=False)\n",
    "        self.layer4 = self._make_layer(block, 512, blocks_num[3], stride=2, dynamic=False)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "    def _make_layer(self, block, channel, block_num, dynamic, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channel != channel * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channel, channel * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(channel * block.expansion))\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channel, channel, downsample=downsample, stride=stride, dynamic = dynamic))\n",
    "        self.in_channel = channel * block.expansion\n",
    "\n",
    "        for _ in range(1, block_num):\n",
    "            layers.append(block(self.in_channel, channel))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "    \n",
    "        feature1 = self.layer1(x)\n",
    "        feature2 = self.layer2(feature1)\n",
    "        feature3 = self.layer3(feature2)\n",
    "        feature4 = self.layer4(feature3)\n",
    "    \n",
    "        x = self.avgpool(feature4)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        x = self.softmax(x)\n",
    "        return x, [feature1, feature2, feature3, feature4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_from_scratch(model, train_loader, val_loader, epochs, learning_rate, device, model_name):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.Adam(params, lr=learning_rate)\n",
    "    #scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "    loss = []\n",
    "    train_error=[]\n",
    "    val_error = []\n",
    "    valdation_error = []\n",
    "    train_loss = []\n",
    "    valdation_loss = []\n",
    "    train_accuraacy = []\n",
    "    valdation_accuracy= []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        valid_acc = 0.0\n",
    "        correct = 0.\n",
    "        total = 0.\n",
    "        V_correct = 0.\n",
    "        V_total = 0.\n",
    "        max_val_acc = 0.0\n",
    "\n",
    "        model.train()\n",
    "        train_bar = tqdm(train_loader, file=sys.stdout)\n",
    "        for step, data in enumerate(train_bar):\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits, hidden = model(images)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #scheduler.step()\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "            pred = logits.data.max(1, keepdim=True)[1]\n",
    "            correct += np.sum(np.squeeze(pred.eq(labels.data.view_as(pred))).cpu().numpy())\n",
    "            total += images.size(0)\n",
    "            train_acc =  correct/total\n",
    "            train_bar.desc = \"train epoch[{}/{}]\".format(epoch + 1, epochs)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_bar = tqdm(val_loader, file=sys.stdout)\n",
    "            for val_data in val_bar:\n",
    "                val_images, val_labels = val_data\n",
    "                val_images, val_labels = val_images.to(device), val_labels.to(device)\n",
    "                outputs, hidden_outputs = model(val_images)\n",
    "                loss = criterion(outputs, val_labels)\n",
    "                valid_loss += loss.item() * val_images.size(0)\n",
    "                pred = outputs.data.max(1, keepdim=True)[1]\n",
    "                V_correct += np.sum(np.squeeze(pred.eq(val_labels.data.view_as(pred))).cpu().numpy())\n",
    "                V_total += val_images.size(0)\n",
    "                val_bar.desc = \"valid epoch[{}/{}]\".format(epoch + 1, epochs)\n",
    "\n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        train_error.append(train_loss)\n",
    "        valid_loss = valid_loss / len(val_loader.dataset)\n",
    "        val_error.append(valid_loss)\n",
    "        train_accuraacy.append( correct / total)\n",
    "        valdation_accuracy.append(V_correct / V_total)\n",
    "        if (V_correct / V_total) > max_val_acc:\n",
    "            max_val_acc = V_correct / V_total\n",
    "            torch.save(model.state_dict(), \"./models/\" + model_name + \".pth\")\n",
    "\n",
    "        print('\\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(train_loss, valid_loss))\n",
    "        print('\\tTrain Accuracy: %.3fd%% (%2d/%2d)\\tValdation Accuracy: %.3fd%% (%2d/%2d) '% (100. * correct / total, correct, total, 100. * V_correct / V_total, V_correct, V_total))\n",
    "\n",
    "    # torch.save(model, f'{model.__class__.__name__}.pt')\n",
    "    print('Finished Training') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader ,device, type=None):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    acc = 0.0\n",
    "    test_loss = 0.0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_bar = tqdm(test_loader, file=sys.stdout)\n",
    "        for test_data in test_bar:\n",
    "            test_images, test_labels = test_data\n",
    "            test_images, test_labels = test_images.to(device), test_labels.to(device)\n",
    "            \n",
    "            outputs, features = model(test_images)\n",
    "            loss = criterion(outputs, test_labels)\n",
    "\n",
    "            predict_y = torch.max(outputs, dim=1)[1]\n",
    "            acc += torch.eq(predict_y, test_labels.to(device)).sum().item()\n",
    "            test_loss += loss.item()\n",
    "            test_bar.desc = \"test\"\n",
    "\n",
    "    test_accurate = acc / test_num\n",
    "    print('test_loss: %.3f  test_accuracy: %.3f' %(test_loss / test_steps, test_accurate * 100))\n",
    "    return test_loss / test_steps, test_accurate * 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet34 3 channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Resnet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch[1/10]: 100%|██████████| 495/495 [02:53<00:00,  2.85it/s]\n",
      "valid epoch[1/10]: 100%|██████████| 4/4 [00:00<00:00,  4.87it/s]\n",
      "\tTraining Loss: 3.883179 \tValidation Loss: 3.881271\n",
      "\tTrain Accuracy: 5.761d% (3648/63325)\tValdation Accuracy: 6.667d% (30/450) \n",
      "train epoch[2/10]: 100%|██████████| 495/495 [02:52<00:00,  2.86it/s]\n",
      "valid epoch[2/10]: 100%|██████████| 4/4 [00:00<00:00,  5.11it/s]\n",
      "\tTraining Loss: 3.870358 \tValidation Loss: 3.873805\n",
      "\tTrain Accuracy: 7.207d% (4564/63325)\tValdation Accuracy: 6.667d% (30/450) \n",
      "train epoch[3/10]: 100%|██████████| 495/495 [02:54<00:00,  2.84it/s]\n",
      "valid epoch[3/10]: 100%|██████████| 4/4 [00:00<00:00,  4.98it/s]\n",
      "\tTraining Loss: 3.853686 \tValidation Loss: 3.852032\n",
      "\tTrain Accuracy: 9.004d% (5702/63325)\tValdation Accuracy: 9.556d% (43/450) \n",
      "train epoch[4/10]: 100%|██████████| 495/495 [02:54<00:00,  2.83it/s]\n",
      "valid epoch[4/10]: 100%|██████████| 4/4 [00:00<00:00,  4.83it/s]\n",
      "\tTraining Loss: 3.842217 \tValidation Loss: 3.837766\n",
      "\tTrain Accuracy: 10.141d% (6422/63325)\tValdation Accuracy: 10.444d% (47/450) \n",
      "train epoch[5/10]: 100%|██████████| 495/495 [02:54<00:00,  2.84it/s]\n",
      "valid epoch[5/10]: 100%|██████████| 4/4 [00:00<00:00,  4.95it/s]\n",
      "\tTraining Loss: 3.834742 \tValidation Loss: 3.860052\n",
      "\tTrain Accuracy: 10.966d% (6944/63325)\tValdation Accuracy: 8.222d% (37/450) \n",
      "train epoch[6/10]: 100%|██████████| 495/495 [02:54<00:00,  2.83it/s]\n",
      "valid epoch[6/10]: 100%|██████████| 4/4 [00:00<00:00,  4.97it/s]\n",
      "\tTraining Loss: 3.828660 \tValidation Loss: 3.814283\n",
      "\tTrain Accuracy: 11.561d% (7321/63325)\tValdation Accuracy: 12.667d% (57/450) \n",
      "train epoch[7/10]: 100%|██████████| 495/495 [02:54<00:00,  2.84it/s]\n",
      "valid epoch[7/10]: 100%|██████████| 4/4 [00:00<00:00,  4.92it/s]\n",
      "\tTraining Loss: 3.821478 \tValidation Loss: 3.830209\n",
      "\tTrain Accuracy: 12.289d% (7782/63325)\tValdation Accuracy: 11.333d% (51/450) \n",
      "train epoch[8/10]: 100%|██████████| 495/495 [02:54<00:00,  2.84it/s]\n",
      "valid epoch[8/10]: 100%|██████████| 4/4 [00:00<00:00,  5.05it/s]\n",
      "\tTraining Loss: 3.814947 \tValidation Loss: 3.807624\n",
      "\tTrain Accuracy: 12.935d% (8191/63325)\tValdation Accuracy: 13.778d% (62/450) \n",
      "train epoch[9/10]: 100%|██████████| 495/495 [02:53<00:00,  2.85it/s]\n",
      "valid epoch[9/10]: 100%|██████████| 4/4 [00:00<00:00,  4.95it/s]\n",
      "\tTraining Loss: 3.805503 \tValidation Loss: 3.816600\n",
      "\tTrain Accuracy: 13.976d% (8850/63325)\tValdation Accuracy: 12.444d% (56/450) \n",
      "train epoch[10/10]: 100%|██████████| 495/495 [02:54<00:00,  2.84it/s]\n",
      "valid epoch[10/10]: 100%|██████████| 4/4 [00:00<00:00,  4.93it/s]\n",
      "\tTraining Loss: 3.798540 \tValidation Loss: 3.793496\n",
      "\tTrain Accuracy: 14.664d% (9286/63325)\tValdation Accuracy: 14.889d% (67/450) \n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "model = ResNet(BasicBlock, [3, 4, 6, 3], num_classes=50)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "train_from_scratch(model, train_loader, val_loader, epochs=num_epochs, learning_rate=lr, device=device, model_name=\"best_resnet34_3channels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Resnet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: 100%|██████████| 4/4 [00:00<00:00,  4.92it/s]\n",
      "test_loss: 3.814  test_accuracy: 11.778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.8143553137779236, 11.777777777777777)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model = ResNet(BasicBlock, [3, 4, 6, 3], num_classes=50).to(device)\n",
    "test_model.load_state_dict(torch.load(os.getcwd() + \"/\" + \"models/best_resnet34_3channels.pth\"))\n",
    "test_model.eval()\n",
    "test(test_model, test_loader=test_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNet                                   [128, 50]                 --\n",
       "├─Conv2d: 1-1                            [128, 64, 128, 128]       1,728\n",
       "├─BatchNorm2d: 1-2                       [128, 64, 128, 128]       128\n",
       "├─ReLU: 1-3                              [128, 64, 128, 128]       --\n",
       "├─MaxPool2d: 1-4                         [128, 64, 64, 64]         --\n",
       "├─Sequential: 1-5                        [128, 64, 64, 64]         --\n",
       "│    └─BasicBlock: 2-1                   [128, 64, 64, 64]         --\n",
       "│    │    └─Conv2d: 3-1                  [128, 64, 64, 64]         36,864\n",
       "│    │    └─BatchNorm2d: 3-2             [128, 64, 64, 64]         128\n",
       "│    │    └─ReLU: 3-3                    [128, 64, 64, 64]         --\n",
       "│    │    └─Conv2d: 3-4                  [128, 64, 64, 64]         36,864\n",
       "│    │    └─BatchNorm2d: 3-5             [128, 64, 64, 64]         128\n",
       "│    │    └─ReLU: 3-6                    [128, 64, 64, 64]         --\n",
       "│    └─BasicBlock: 2-2                   [128, 64, 64, 64]         --\n",
       "│    │    └─Conv2d: 3-7                  [128, 64, 64, 64]         36,864\n",
       "│    │    └─BatchNorm2d: 3-8             [128, 64, 64, 64]         128\n",
       "│    │    └─ReLU: 3-9                    [128, 64, 64, 64]         --\n",
       "│    │    └─Conv2d: 3-10                 [128, 64, 64, 64]         36,864\n",
       "│    │    └─BatchNorm2d: 3-11            [128, 64, 64, 64]         128\n",
       "│    │    └─ReLU: 3-12                   [128, 64, 64, 64]         --\n",
       "│    └─BasicBlock: 2-3                   [128, 64, 64, 64]         --\n",
       "│    │    └─Conv2d: 3-13                 [128, 64, 64, 64]         36,864\n",
       "│    │    └─BatchNorm2d: 3-14            [128, 64, 64, 64]         128\n",
       "│    │    └─ReLU: 3-15                   [128, 64, 64, 64]         --\n",
       "│    │    └─Conv2d: 3-16                 [128, 64, 64, 64]         36,864\n",
       "│    │    └─BatchNorm2d: 3-17            [128, 64, 64, 64]         128\n",
       "│    │    └─ReLU: 3-18                   [128, 64, 64, 64]         --\n",
       "├─Sequential: 1-6                        [128, 128, 32, 32]        --\n",
       "│    └─BasicBlock: 2-4                   [128, 128, 32, 32]        --\n",
       "│    │    └─Sequential: 3-19             [128, 128, 32, 32]        8,448\n",
       "│    │    └─Conv2d: 3-20                 [128, 128, 32, 32]        73,728\n",
       "│    │    └─BatchNorm2d: 3-21            [128, 128, 32, 32]        256\n",
       "│    │    └─ReLU: 3-22                   [128, 128, 32, 32]        --\n",
       "│    │    └─Conv2d: 3-23                 [128, 128, 32, 32]        147,456\n",
       "│    │    └─BatchNorm2d: 3-24            [128, 128, 32, 32]        256\n",
       "│    │    └─ReLU: 3-25                   [128, 128, 32, 32]        --\n",
       "│    └─BasicBlock: 2-5                   [128, 128, 32, 32]        --\n",
       "│    │    └─Conv2d: 3-26                 [128, 128, 32, 32]        147,456\n",
       "│    │    └─BatchNorm2d: 3-27            [128, 128, 32, 32]        256\n",
       "│    │    └─ReLU: 3-28                   [128, 128, 32, 32]        --\n",
       "│    │    └─Conv2d: 3-29                 [128, 128, 32, 32]        147,456\n",
       "│    │    └─BatchNorm2d: 3-30            [128, 128, 32, 32]        256\n",
       "│    │    └─ReLU: 3-31                   [128, 128, 32, 32]        --\n",
       "│    └─BasicBlock: 2-6                   [128, 128, 32, 32]        --\n",
       "│    │    └─Conv2d: 3-32                 [128, 128, 32, 32]        147,456\n",
       "│    │    └─BatchNorm2d: 3-33            [128, 128, 32, 32]        256\n",
       "│    │    └─ReLU: 3-34                   [128, 128, 32, 32]        --\n",
       "│    │    └─Conv2d: 3-35                 [128, 128, 32, 32]        147,456\n",
       "│    │    └─BatchNorm2d: 3-36            [128, 128, 32, 32]        256\n",
       "│    │    └─ReLU: 3-37                   [128, 128, 32, 32]        --\n",
       "│    └─BasicBlock: 2-7                   [128, 128, 32, 32]        --\n",
       "│    │    └─Conv2d: 3-38                 [128, 128, 32, 32]        147,456\n",
       "│    │    └─BatchNorm2d: 3-39            [128, 128, 32, 32]        256\n",
       "│    │    └─ReLU: 3-40                   [128, 128, 32, 32]        --\n",
       "│    │    └─Conv2d: 3-41                 [128, 128, 32, 32]        147,456\n",
       "│    │    └─BatchNorm2d: 3-42            [128, 128, 32, 32]        256\n",
       "│    │    └─ReLU: 3-43                   [128, 128, 32, 32]        --\n",
       "├─Sequential: 1-7                        [128, 256, 16, 16]        --\n",
       "│    └─BasicBlock: 2-8                   [128, 256, 16, 16]        --\n",
       "│    │    └─Sequential: 3-44             [128, 256, 16, 16]        33,280\n",
       "│    │    └─Conv2d: 3-45                 [128, 256, 16, 16]        294,912\n",
       "│    │    └─BatchNorm2d: 3-46            [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-47                   [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-48                 [128, 256, 16, 16]        589,824\n",
       "│    │    └─BatchNorm2d: 3-49            [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-50                   [128, 256, 16, 16]        --\n",
       "│    └─BasicBlock: 2-9                   [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-51                 [128, 256, 16, 16]        589,824\n",
       "│    │    └─BatchNorm2d: 3-52            [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-53                   [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-54                 [128, 256, 16, 16]        589,824\n",
       "│    │    └─BatchNorm2d: 3-55            [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-56                   [128, 256, 16, 16]        --\n",
       "│    └─BasicBlock: 2-10                  [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-57                 [128, 256, 16, 16]        589,824\n",
       "│    │    └─BatchNorm2d: 3-58            [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-59                   [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-60                 [128, 256, 16, 16]        589,824\n",
       "│    │    └─BatchNorm2d: 3-61            [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-62                   [128, 256, 16, 16]        --\n",
       "│    └─BasicBlock: 2-11                  [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-63                 [128, 256, 16, 16]        589,824\n",
       "│    │    └─BatchNorm2d: 3-64            [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-65                   [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-66                 [128, 256, 16, 16]        589,824\n",
       "│    │    └─BatchNorm2d: 3-67            [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-68                   [128, 256, 16, 16]        --\n",
       "│    └─BasicBlock: 2-12                  [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-69                 [128, 256, 16, 16]        589,824\n",
       "│    │    └─BatchNorm2d: 3-70            [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-71                   [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-72                 [128, 256, 16, 16]        589,824\n",
       "│    │    └─BatchNorm2d: 3-73            [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-74                   [128, 256, 16, 16]        --\n",
       "│    └─BasicBlock: 2-13                  [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-75                 [128, 256, 16, 16]        589,824\n",
       "│    │    └─BatchNorm2d: 3-76            [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-77                   [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-78                 [128, 256, 16, 16]        589,824\n",
       "│    │    └─BatchNorm2d: 3-79            [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-80                   [128, 256, 16, 16]        --\n",
       "├─Sequential: 1-8                        [128, 512, 8, 8]          --\n",
       "│    └─BasicBlock: 2-14                  [128, 512, 8, 8]          --\n",
       "│    │    └─Sequential: 3-81             [128, 512, 8, 8]          132,096\n",
       "│    │    └─Conv2d: 3-82                 [128, 512, 8, 8]          1,179,648\n",
       "│    │    └─BatchNorm2d: 3-83            [128, 512, 8, 8]          1,024\n",
       "│    │    └─ReLU: 3-84                   [128, 512, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-85                 [128, 512, 8, 8]          2,359,296\n",
       "│    │    └─BatchNorm2d: 3-86            [128, 512, 8, 8]          1,024\n",
       "│    │    └─ReLU: 3-87                   [128, 512, 8, 8]          --\n",
       "│    └─BasicBlock: 2-15                  [128, 512, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-88                 [128, 512, 8, 8]          2,359,296\n",
       "│    │    └─BatchNorm2d: 3-89            [128, 512, 8, 8]          1,024\n",
       "│    │    └─ReLU: 3-90                   [128, 512, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-91                 [128, 512, 8, 8]          2,359,296\n",
       "│    │    └─BatchNorm2d: 3-92            [128, 512, 8, 8]          1,024\n",
       "│    │    └─ReLU: 3-93                   [128, 512, 8, 8]          --\n",
       "│    └─BasicBlock: 2-16                  [128, 512, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-94                 [128, 512, 8, 8]          2,359,296\n",
       "│    │    └─BatchNorm2d: 3-95            [128, 512, 8, 8]          1,024\n",
       "│    │    └─ReLU: 3-96                   [128, 512, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-97                 [128, 512, 8, 8]          2,359,296\n",
       "│    │    └─BatchNorm2d: 3-98            [128, 512, 8, 8]          1,024\n",
       "│    │    └─ReLU: 3-99                   [128, 512, 8, 8]          --\n",
       "├─AdaptiveAvgPool2d: 1-9                 [128, 512, 1, 1]          --\n",
       "├─Linear: 1-10                           [128, 50]                 25,650\n",
       "├─Softmax: 1-11                          [128, 50]                 --\n",
       "==========================================================================================\n",
       "Total params: 21,302,642\n",
       "Trainable params: 21,302,642\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 596.33\n",
       "==========================================================================================\n",
       "Input size (MB): 25.17\n",
       "Forward/backward pass size (MB): 9999.27\n",
       "Params size (MB): 85.21\n",
       "Estimated Total Size (MB): 10109.65\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, input_size=(128, 3, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  21.3 M, 100.000% Params, 4.67 GMac, 99.877% MACs, \n",
      "  (conv1): Conv2d(1.73 k, 0.008% Params, 28.31 MMac, 0.605% MACs, 3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, 0.001% Params, 2.1 MMac, 0.045% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(0, 0.000% Params, 1.05 MMac, 0.022% MACs, inplace=True)\n",
      "  (maxpool): MaxPool2d(0, 0.000% Params, 1.05 MMac, 0.022% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    221.95 k, 1.042% Params, 910.69 MMac, 19.459% MACs, \n",
      "    (0): BasicBlock(\n",
      "      73.98 k, 0.347% Params, 303.56 MMac, 6.486% MACs, \n",
      "      (conv1): Conv2d(36.86 k, 0.173% Params, 150.99 MMac, 3.226% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, 0.001% Params, 524.29 KMac, 0.011% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 524.29 KMac, 0.011% MACs, )\n",
      "      (conv2): Conv2d(36.86 k, 0.173% Params, 150.99 MMac, 3.226% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, 0.001% Params, 524.29 KMac, 0.011% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      73.98 k, 0.347% Params, 303.56 MMac, 6.486% MACs, \n",
      "      (conv1): Conv2d(36.86 k, 0.173% Params, 150.99 MMac, 3.226% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, 0.001% Params, 524.29 KMac, 0.011% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 524.29 KMac, 0.011% MACs, )\n",
      "      (conv2): Conv2d(36.86 k, 0.173% Params, 150.99 MMac, 3.226% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, 0.001% Params, 524.29 KMac, 0.011% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      73.98 k, 0.347% Params, 303.56 MMac, 6.486% MACs, \n",
      "      (conv1): Conv2d(36.86 k, 0.173% Params, 150.99 MMac, 3.226% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, 0.001% Params, 524.29 KMac, 0.011% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 524.29 KMac, 0.011% MACs, )\n",
      "      (conv2): Conv2d(36.86 k, 0.173% Params, 150.99 MMac, 3.226% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, 0.001% Params, 524.29 KMac, 0.011% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    1.12 M, 5.241% Params, 1.14 GMac, 24.450% MACs, \n",
      "    (0): BasicBlock(\n",
      "      230.14 k, 1.080% Params, 235.93 MMac, 5.041% MACs, \n",
      "      (conv1): Conv2d(73.73 k, 0.346% Params, 75.5 MMac, 1.613% MACs, 64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, 0.001% Params, 262.14 KMac, 0.006% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 262.14 KMac, 0.006% MACs, )\n",
      "      (conv2): Conv2d(147.46 k, 0.692% Params, 150.99 MMac, 3.226% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, 0.001% Params, 262.14 KMac, 0.006% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        8.45 k, 0.040% Params, 8.65 MMac, 0.185% MACs, \n",
      "        (0): Conv2d(8.19 k, 0.038% Params, 8.39 MMac, 0.179% MACs, 64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, 0.001% Params, 262.14 KMac, 0.006% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      295.42 k, 1.387% Params, 302.78 MMac, 6.469% MACs, \n",
      "      (conv1): Conv2d(147.46 k, 0.692% Params, 150.99 MMac, 3.226% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, 0.001% Params, 262.14 KMac, 0.006% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 262.14 KMac, 0.006% MACs, )\n",
      "      (conv2): Conv2d(147.46 k, 0.692% Params, 150.99 MMac, 3.226% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, 0.001% Params, 262.14 KMac, 0.006% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      295.42 k, 1.387% Params, 302.78 MMac, 6.469% MACs, \n",
      "      (conv1): Conv2d(147.46 k, 0.692% Params, 150.99 MMac, 3.226% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, 0.001% Params, 262.14 KMac, 0.006% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 262.14 KMac, 0.006% MACs, )\n",
      "      (conv2): Conv2d(147.46 k, 0.692% Params, 150.99 MMac, 3.226% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, 0.001% Params, 262.14 KMac, 0.006% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      295.42 k, 1.387% Params, 302.78 MMac, 6.469% MACs, \n",
      "      (conv1): Conv2d(147.46 k, 0.692% Params, 150.99 MMac, 3.226% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, 0.001% Params, 262.14 KMac, 0.006% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 262.14 KMac, 0.006% MACs, )\n",
      "      (conv2): Conv2d(147.46 k, 0.692% Params, 150.99 MMac, 3.226% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, 0.001% Params, 262.14 KMac, 0.006% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    6.82 M, 32.026% Params, 1.75 GMac, 37.335% MACs, \n",
      "    (0): BasicBlock(\n",
      "      919.04 k, 4.314% Params, 235.41 MMac, 5.030% MACs, \n",
      "      (conv1): Conv2d(294.91 k, 1.384% Params, 75.5 MMac, 1.613% MACs, 128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 131.07 KMac, 0.003% MACs, )\n",
      "      (conv2): Conv2d(589.82 k, 2.769% Params, 150.99 MMac, 3.226% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        33.28 k, 0.156% Params, 8.52 MMac, 0.182% MACs, \n",
      "        (0): Conv2d(32.77 k, 0.154% Params, 8.39 MMac, 0.179% MACs, 128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      1.18 M, 5.542% Params, 302.38 MMac, 6.461% MACs, \n",
      "      (conv1): Conv2d(589.82 k, 2.769% Params, 150.99 MMac, 3.226% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 131.07 KMac, 0.003% MACs, )\n",
      "      (conv2): Conv2d(589.82 k, 2.769% Params, 150.99 MMac, 3.226% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      1.18 M, 5.542% Params, 302.38 MMac, 6.461% MACs, \n",
      "      (conv1): Conv2d(589.82 k, 2.769% Params, 150.99 MMac, 3.226% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 131.07 KMac, 0.003% MACs, )\n",
      "      (conv2): Conv2d(589.82 k, 2.769% Params, 150.99 MMac, 3.226% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      1.18 M, 5.542% Params, 302.38 MMac, 6.461% MACs, \n",
      "      (conv1): Conv2d(589.82 k, 2.769% Params, 150.99 MMac, 3.226% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 131.07 KMac, 0.003% MACs, )\n",
      "      (conv2): Conv2d(589.82 k, 2.769% Params, 150.99 MMac, 3.226% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): BasicBlock(\n",
      "      1.18 M, 5.542% Params, 302.38 MMac, 6.461% MACs, \n",
      "      (conv1): Conv2d(589.82 k, 2.769% Params, 150.99 MMac, 3.226% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 131.07 KMac, 0.003% MACs, )\n",
      "      (conv2): Conv2d(589.82 k, 2.769% Params, 150.99 MMac, 3.226% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      1.18 M, 5.542% Params, 302.38 MMac, 6.461% MACs, \n",
      "      (conv1): Conv2d(589.82 k, 2.769% Params, 150.99 MMac, 3.226% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 131.07 KMac, 0.003% MACs, )\n",
      "      (conv2): Conv2d(589.82 k, 2.769% Params, 150.99 MMac, 3.226% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    13.11 M, 61.562% Params, 839.52 MMac, 17.938% MACs, \n",
      "    (0): BasicBlock(\n",
      "      3.67 M, 17.242% Params, 235.14 MMac, 5.024% MACs, \n",
      "      (conv1): Conv2d(1.18 M, 5.538% Params, 75.5 MMac, 1.613% MACs, 256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1.02 k, 0.005% Params, 65.54 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 65.54 KMac, 0.001% MACs, )\n",
      "      (conv2): Conv2d(2.36 M, 11.075% Params, 150.99 MMac, 3.226% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1.02 k, 0.005% Params, 65.54 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        132.1 k, 0.620% Params, 8.45 MMac, 0.181% MACs, \n",
      "        (0): Conv2d(131.07 k, 0.615% Params, 8.39 MMac, 0.179% MACs, 256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1.02 k, 0.005% Params, 65.54 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      4.72 M, 22.160% Params, 302.19 MMac, 6.457% MACs, \n",
      "      (conv1): Conv2d(2.36 M, 11.075% Params, 150.99 MMac, 3.226% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1.02 k, 0.005% Params, 65.54 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 65.54 KMac, 0.001% MACs, )\n",
      "      (conv2): Conv2d(2.36 M, 11.075% Params, 150.99 MMac, 3.226% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1.02 k, 0.005% Params, 65.54 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      4.72 M, 22.160% Params, 302.19 MMac, 6.457% MACs, \n",
      "      (conv1): Conv2d(2.36 M, 11.075% Params, 150.99 MMac, 3.226% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1.02 k, 0.005% Params, 65.54 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 65.54 KMac, 0.001% MACs, )\n",
      "      (conv2): Conv2d(2.36 M, 11.075% Params, 150.99 MMac, 3.226% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1.02 k, 0.005% Params, 65.54 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 32.77 KMac, 0.001% MACs, output_size=(1, 1))\n",
      "  (fc): Linear(25.65 k, 0.120% Params, 25.65 KMac, 0.001% MACs, in_features=512, out_features=50, bias=True)\n",
      "  (softmax): Softmax(0, 0.000% Params, 0.0 Mac, 0.000% MACs, dim=1)\n",
      ")\n",
      "FLOPS: 4.68 GMac\n",
      "Parameters: 21.3 M\n"
     ]
    }
   ],
   "source": [
    "flops, params = get_model_complexity_info(model, (3, 128, 128), as_strings=True, print_per_layer_stat=True)\n",
    "\n",
    "print(f\"FLOPS: {flops}\")\n",
    "print(f\"Parameters: {params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DynamicResnet34 3channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Dynamic Resnet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch[1/10]: 100%|██████████| 495/495 [03:01<00:00,  2.72it/s]\n",
      "valid epoch[1/10]: 100%|██████████| 4/4 [00:00<00:00,  4.88it/s]\n",
      "\tTraining Loss: 3.877905 \tValidation Loss: 3.882598\n",
      "\tTrain Accuracy: 6.433d% (4074/63325)\tValdation Accuracy: 5.778d% (26/450) \n",
      "train epoch[2/10]: 100%|██████████| 495/495 [03:01<00:00,  2.73it/s]\n",
      "valid epoch[2/10]: 100%|██████████| 4/4 [00:00<00:00,  4.90it/s]\n",
      "\tTraining Loss: 3.854722 \tValidation Loss: 3.843908\n",
      "\tTrain Accuracy: 8.881d% (5624/63325)\tValdation Accuracy: 10.000d% (45/450) \n",
      "train epoch[3/10]: 100%|██████████| 495/495 [03:02<00:00,  2.71it/s]\n",
      "valid epoch[3/10]: 100%|██████████| 4/4 [00:00<00:00,  4.91it/s]\n",
      "\tTraining Loss: 3.846102 \tValidation Loss: 3.841099\n",
      "\tTrain Accuracy: 9.709d% (6148/63325)\tValdation Accuracy: 10.889d% (49/450) \n",
      "train epoch[4/10]: 100%|██████████| 495/495 [03:01<00:00,  2.72it/s]\n",
      "valid epoch[4/10]: 100%|██████████| 4/4 [00:00<00:00,  4.87it/s]\n",
      "\tTraining Loss: 3.836910 \tValidation Loss: 3.832647\n",
      "\tTrain Accuracy: 10.730d% (6795/63325)\tValdation Accuracy: 10.667d% (48/450) \n",
      "train epoch[5/10]: 100%|██████████| 495/495 [03:03<00:00,  2.70it/s]\n",
      "valid epoch[5/10]: 100%|██████████| 4/4 [00:00<00:00,  4.86it/s]\n",
      "\tTraining Loss: 3.828022 \tValidation Loss: 3.829474\n",
      "\tTrain Accuracy: 11.597d% (7344/63325)\tValdation Accuracy: 11.778d% (53/450) \n",
      "train epoch[6/10]: 100%|██████████| 495/495 [03:01<00:00,  2.73it/s]\n",
      "valid epoch[6/10]: 100%|██████████| 4/4 [00:00<00:00,  4.94it/s]\n",
      "\tTraining Loss: 3.817381 \tValidation Loss: 3.820908\n",
      "\tTrain Accuracy: 12.741d% (8068/63325)\tValdation Accuracy: 12.222d% (55/450) \n",
      "train epoch[7/10]: 100%|██████████| 495/495 [02:59<00:00,  2.76it/s]\n",
      "valid epoch[7/10]: 100%|██████████| 4/4 [00:00<00:00,  4.94it/s]\n",
      "\tTraining Loss: 3.808939 \tValidation Loss: 3.797696\n",
      "\tTrain Accuracy: 13.519d% (8561/63325)\tValdation Accuracy: 15.111d% (68/450) \n",
      "train epoch[8/10]: 100%|██████████| 495/495 [02:59<00:00,  2.76it/s]\n",
      "valid epoch[8/10]: 100%|██████████| 4/4 [00:00<00:00,  4.99it/s]\n",
      "\tTraining Loss: 3.801487 \tValidation Loss: 3.812382\n",
      "\tTrain Accuracy: 14.290d% (9049/63325)\tValdation Accuracy: 12.889d% (58/450) \n",
      "train epoch[9/10]: 100%|██████████| 495/495 [03:00<00:00,  2.74it/s]\n",
      "valid epoch[9/10]: 100%|██████████| 4/4 [00:00<00:00,  4.93it/s]\n",
      "\tTraining Loss: 3.789438 \tValidation Loss: 3.799500\n",
      "\tTrain Accuracy: 15.593d% (9874/63325)\tValdation Accuracy: 14.889d% (67/450) \n",
      "train epoch[10/10]: 100%|██████████| 495/495 [03:01<00:00,  2.73it/s]\n",
      "valid epoch[10/10]: 100%|██████████| 4/4 [00:00<00:00,  4.94it/s]\n",
      "\tTraining Loss: 3.782452 \tValidation Loss: 3.781935\n",
      "\tTrain Accuracy: 16.272d% (10304/63325)\tValdation Accuracy: 16.444d% (74/450) \n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "dynamic_model = DynamicResNet(DynamicBasicBlock, [3, 4, 6, 3], num_classes=50)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dynamic_model.to(device)\n",
    "train_from_scratch(dynamic_model, train_loader, val_loader, epochs=num_epochs, learning_rate=lr, device=device, model_name=\"best_dynamic_resnet34_3channels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Dynamic Resnet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: 100%|██████████| 4/4 [00:00<00:00,  4.88it/s]\n",
      "test_loss: 3.773  test_accuracy: 16.000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.7726109623908997, 16.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model = DynamicResNet(DynamicBasicBlock, [3, 4, 6, 3], num_classes=50).to(device)\n",
    "test_model.load_state_dict(torch.load(os.getcwd() + \"/\" + \"models/best_dynamic_resnet34_3channels.pth\"))\n",
    "test_model.eval()\n",
    "test(test_model, test_loader=test_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DynamicResNet(\n",
      "  21.24 M, 98.597% Params, 4.35 GMac, 99.848% MACs, \n",
      "  (conv1): DynamicConv(\n",
      "    21, 0.000% Params, 49.18 KMac, 0.001% MACs, \n",
      "    (attention): attention2d(\n",
      "      21, 0.000% Params, 49.18 KMac, 0.001% MACs, \n",
      "      (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 49.15 KMac, 0.001% MACs, output_size=1)\n",
      "      (cal): Sequential(\n",
      "        21, 0.000% Params, 24.0 Mac, 0.000% MACs, \n",
      "        (0): Conv2d(9, 0.000% Params, 9.0 Mac, 0.000% MACs, 3, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): ReLU(0, 0.000% Params, 3.0 Mac, 0.000% MACs, )\n",
      "        (2): Conv2d(12, 0.000% Params, 12.0 Mac, 0.000% MACs, 3, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (bn1): BatchNorm2d(128, 0.001% Params, 2.1 MMac, 0.048% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(0, 0.000% Params, 1.05 MMac, 0.024% MACs, inplace=True)\n",
      "  (maxpool): MaxPool2d(0, 0.000% Params, 1.05 MMac, 0.024% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    157.18 k, 0.730% Params, 610.28 MMac, 14.016% MACs, \n",
      "    (0): DynamicBasicBlock(\n",
      "      8.96 k, 0.042% Params, 2.11 MMac, 0.048% MACs, \n",
      "      (conv1): DynamicConv(\n",
      "        4.35 k, 0.020% Params, 266.56 KMac, 0.006% MACs, \n",
      "        (attention): attention2d(\n",
      "          4.35 k, 0.020% Params, 266.56 KMac, 0.006% MACs, \n",
      "          (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 262.14 KMac, 0.006% MACs, output_size=1)\n",
      "          (cal): Sequential(\n",
      "            4.35 k, 0.020% Params, 4.42 KMac, 0.000% MACs, \n",
      "            (0): Conv2d(4.1 k, 0.019% Params, 4.1 KMac, 0.000% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): ReLU(0, 0.000% Params, 64.0 Mac, 0.000% MACs, )\n",
      "            (2): Conv2d(256, 0.001% Params, 256.0 Mac, 0.000% MACs, 64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv2): DynamicConv(\n",
      "        4.35 k, 0.020% Params, 266.56 KMac, 0.006% MACs, \n",
      "        (attention): attention2d(\n",
      "          4.35 k, 0.020% Params, 266.56 KMac, 0.006% MACs, \n",
      "          (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 262.14 KMac, 0.006% MACs, output_size=1)\n",
      "          (cal): Sequential(\n",
      "            4.35 k, 0.020% Params, 4.42 KMac, 0.000% MACs, \n",
      "            (0): Conv2d(4.1 k, 0.019% Params, 4.1 KMac, 0.000% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): ReLU(0, 0.000% Params, 64.0 Mac, 0.000% MACs, )\n",
      "            (2): Conv2d(256, 0.001% Params, 256.0 Mac, 0.000% MACs, 64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (bn1): BatchNorm2d(128, 0.001% Params, 524.29 KMac, 0.012% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 524.29 KMac, 0.012% MACs, )\n",
      "      (bn2): BatchNorm2d(128, 0.001% Params, 524.29 KMac, 0.012% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): DynamicBasicBlock(\n",
      "      74.11 k, 0.344% Params, 304.09 MMac, 6.984% MACs, \n",
      "      (conv1): Conv2d(36.93 k, 0.171% Params, 151.26 MMac, 3.474% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(36.93 k, 0.171% Params, 151.26 MMac, 3.474% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, 0.001% Params, 524.29 KMac, 0.012% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 524.29 KMac, 0.012% MACs, )\n",
      "      (bn2): BatchNorm2d(128, 0.001% Params, 524.29 KMac, 0.012% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): DynamicBasicBlock(\n",
      "      74.11 k, 0.344% Params, 304.09 MMac, 6.984% MACs, \n",
      "      (conv1): Conv2d(36.93 k, 0.171% Params, 151.26 MMac, 3.474% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(36.93 k, 0.171% Params, 151.26 MMac, 3.474% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, 0.001% Params, 524.29 KMac, 0.012% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 524.29 KMac, 0.012% MACs, )\n",
      "      (bn2): BatchNorm2d(128, 0.001% Params, 524.29 KMac, 0.012% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    1.12 M, 5.186% Params, 1.15 GMac, 26.303% MACs, \n",
      "    (0): DynamicBasicBlock(\n",
      "      230.4 k, 1.069% Params, 236.19 MMac, 5.424% MACs, \n",
      "      (conv1): Conv2d(73.86 k, 0.343% Params, 75.63 MMac, 1.737% MACs, 64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (conv2): Conv2d(147.58 k, 0.685% Params, 151.13 MMac, 3.471% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, 0.001% Params, 262.14 KMac, 0.006% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 262.14 KMac, 0.006% MACs, )\n",
      "      (bn2): BatchNorm2d(256, 0.001% Params, 262.14 KMac, 0.006% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        8.45 k, 0.039% Params, 8.65 MMac, 0.199% MACs, \n",
      "        (0): Conv2d(8.19 k, 0.038% Params, 8.39 MMac, 0.193% MACs, 64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, 0.001% Params, 262.14 KMac, 0.006% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): DynamicBasicBlock(\n",
      "      295.68 k, 1.372% Params, 303.04 MMac, 6.959% MACs, \n",
      "      (conv1): Conv2d(147.58 k, 0.685% Params, 151.13 MMac, 3.471% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(147.58 k, 0.685% Params, 151.13 MMac, 3.471% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, 0.001% Params, 262.14 KMac, 0.006% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 262.14 KMac, 0.006% MACs, )\n",
      "      (bn2): BatchNorm2d(256, 0.001% Params, 262.14 KMac, 0.006% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): DynamicBasicBlock(\n",
      "      295.68 k, 1.372% Params, 303.04 MMac, 6.959% MACs, \n",
      "      (conv1): Conv2d(147.58 k, 0.685% Params, 151.13 MMac, 3.471% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(147.58 k, 0.685% Params, 151.13 MMac, 3.471% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, 0.001% Params, 262.14 KMac, 0.006% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 262.14 KMac, 0.006% MACs, )\n",
      "      (bn2): BatchNorm2d(256, 0.001% Params, 262.14 KMac, 0.006% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): DynamicBasicBlock(\n",
      "      295.68 k, 1.372% Params, 303.04 MMac, 6.959% MACs, \n",
      "      (conv1): Conv2d(147.58 k, 0.685% Params, 151.13 MMac, 3.471% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(147.58 k, 0.685% Params, 151.13 MMac, 3.471% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, 0.001% Params, 262.14 KMac, 0.006% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 262.14 KMac, 0.006% MACs, )\n",
      "      (bn2): BatchNorm2d(256, 0.001% Params, 262.14 KMac, 0.006% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    6.83 M, 31.679% Params, 1.75 GMac, 40.147% MACs, \n",
      "    (0): DynamicBasicBlock(\n",
      "      919.55 k, 4.268% Params, 235.54 MMac, 5.409% MACs, \n",
      "      (conv1): Conv2d(295.17 k, 1.370% Params, 75.56 MMac, 1.735% MACs, 128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (conv2): Conv2d(590.08 k, 2.739% Params, 151.06 MMac, 3.469% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 131.07 KMac, 0.003% MACs, )\n",
      "      (bn2): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        33.28 k, 0.154% Params, 8.52 MMac, 0.196% MACs, \n",
      "        (0): Conv2d(32.77 k, 0.152% Params, 8.39 MMac, 0.193% MACs, 128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): DynamicBasicBlock(\n",
      "      1.18 M, 5.482% Params, 302.51 MMac, 6.947% MACs, \n",
      "      (conv1): Conv2d(590.08 k, 2.739% Params, 151.06 MMac, 3.469% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(590.08 k, 2.739% Params, 151.06 MMac, 3.469% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 131.07 KMac, 0.003% MACs, )\n",
      "      (bn2): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): DynamicBasicBlock(\n",
      "      1.18 M, 5.482% Params, 302.51 MMac, 6.947% MACs, \n",
      "      (conv1): Conv2d(590.08 k, 2.739% Params, 151.06 MMac, 3.469% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(590.08 k, 2.739% Params, 151.06 MMac, 3.469% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 131.07 KMac, 0.003% MACs, )\n",
      "      (bn2): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): DynamicBasicBlock(\n",
      "      1.18 M, 5.482% Params, 302.51 MMac, 6.947% MACs, \n",
      "      (conv1): Conv2d(590.08 k, 2.739% Params, 151.06 MMac, 3.469% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(590.08 k, 2.739% Params, 151.06 MMac, 3.469% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 131.07 KMac, 0.003% MACs, )\n",
      "      (bn2): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): DynamicBasicBlock(\n",
      "      1.18 M, 5.482% Params, 302.51 MMac, 6.947% MACs, \n",
      "      (conv1): Conv2d(590.08 k, 2.739% Params, 151.06 MMac, 3.469% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(590.08 k, 2.739% Params, 151.06 MMac, 3.469% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 131.07 KMac, 0.003% MACs, )\n",
      "      (bn2): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): DynamicBasicBlock(\n",
      "      1.18 M, 5.482% Params, 302.51 MMac, 6.947% MACs, \n",
      "      (conv1): Conv2d(590.08 k, 2.739% Params, 151.06 MMac, 3.469% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(590.08 k, 2.739% Params, 151.06 MMac, 3.469% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 131.07 KMac, 0.003% MACs, )\n",
      "      (bn2): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    13.12 M, 60.882% Params, 839.71 MMac, 19.285% MACs, \n",
      "    (0): DynamicBasicBlock(\n",
      "      3.67 M, 17.053% Params, 235.21 MMac, 5.402% MACs, \n",
      "      (conv1): Conv2d(1.18 M, 5.477% Params, 75.53 MMac, 1.735% MACs, 256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (conv2): Conv2d(2.36 M, 10.953% Params, 151.03 MMac, 3.468% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(1.02 k, 0.005% Params, 65.54 KMac, 0.002% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 65.54 KMac, 0.002% MACs, )\n",
      "      (bn2): BatchNorm2d(1.02 k, 0.005% Params, 65.54 KMac, 0.002% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        132.1 k, 0.613% Params, 8.45 MMac, 0.194% MACs, \n",
      "        (0): Conv2d(131.07 k, 0.608% Params, 8.39 MMac, 0.193% MACs, 256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1.02 k, 0.005% Params, 65.54 KMac, 0.002% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): DynamicBasicBlock(\n",
      "      4.72 M, 21.915% Params, 302.25 MMac, 6.941% MACs, \n",
      "      (conv1): Conv2d(2.36 M, 10.953% Params, 151.03 MMac, 3.468% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(2.36 M, 10.953% Params, 151.03 MMac, 3.468% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(1.02 k, 0.005% Params, 65.54 KMac, 0.002% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 65.54 KMac, 0.002% MACs, )\n",
      "      (bn2): BatchNorm2d(1.02 k, 0.005% Params, 65.54 KMac, 0.002% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): DynamicBasicBlock(\n",
      "      4.72 M, 21.915% Params, 302.25 MMac, 6.941% MACs, \n",
      "      (conv1): Conv2d(2.36 M, 10.953% Params, 151.03 MMac, 3.468% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(2.36 M, 10.953% Params, 151.03 MMac, 3.468% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(1.02 k, 0.005% Params, 65.54 KMac, 0.002% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 65.54 KMac, 0.002% MACs, )\n",
      "      (bn2): BatchNorm2d(1.02 k, 0.005% Params, 65.54 KMac, 0.002% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 32.77 KMac, 0.001% MACs, output_size=(1, 1))\n",
      "  (fc): Linear(25.65 k, 0.119% Params, 25.65 KMac, 0.001% MACs, in_features=512, out_features=50, bias=True)\n",
      "  (softmax): Softmax(0, 0.000% Params, 0.0 Mac, 0.000% MACs, dim=1)\n",
      ")\n",
      "FLOPS: 4.35 GMac\n",
      "Parameters: 21.55 M\n"
     ]
    }
   ],
   "source": [
    "flops, params = get_model_complexity_info(dynamic_model, (3, 128, 128), as_strings=True, print_per_layer_stat=True)\n",
    "\n",
    "print(f\"FLOPS: {flops}\")\n",
    "print(f\"Parameters: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "DynamicResNet                                      [128, 50]                 --\n",
       "├─DynamicConv: 1-1                                 [128, 64, 128, 128]       6,912\n",
       "│    └─attention2d: 2-1                            [128, 4]                  --\n",
       "│    │    └─AdaptiveAvgPool2d: 3-1                 [128, 3, 1, 1]            --\n",
       "│    │    └─Sequential: 3-2                        [128, 4, 1, 1]            21\n",
       "├─BatchNorm2d: 1-2                                 [128, 64, 128, 128]       128\n",
       "├─ReLU: 1-3                                        [128, 64, 128, 128]       --\n",
       "├─MaxPool2d: 1-4                                   [128, 64, 64, 64]         --\n",
       "├─Sequential: 1-5                                  [128, 64, 64, 64]         --\n",
       "│    └─DynamicBasicBlock: 2-2                      [128, 64, 64, 64]         --\n",
       "│    │    └─DynamicConv: 3-3                       [128, 64, 64, 64]         152,064\n",
       "│    │    └─BatchNorm2d: 3-4                       [128, 64, 64, 64]         128\n",
       "│    │    └─ReLU: 3-5                              [128, 64, 64, 64]         --\n",
       "│    │    └─DynamicConv: 3-6                       [128, 64, 64, 64]         152,064\n",
       "│    │    └─BatchNorm2d: 3-7                       [128, 64, 64, 64]         128\n",
       "│    │    └─ReLU: 3-8                              [128, 64, 64, 64]         --\n",
       "│    └─DynamicBasicBlock: 2-3                      [128, 64, 64, 64]         --\n",
       "│    │    └─Conv2d: 3-9                            [128, 64, 64, 64]         36,928\n",
       "│    │    └─BatchNorm2d: 3-10                      [128, 64, 64, 64]         128\n",
       "│    │    └─ReLU: 3-11                             [128, 64, 64, 64]         --\n",
       "│    │    └─Conv2d: 3-12                           [128, 64, 64, 64]         36,928\n",
       "│    │    └─BatchNorm2d: 3-13                      [128, 64, 64, 64]         128\n",
       "│    │    └─ReLU: 3-14                             [128, 64, 64, 64]         --\n",
       "│    └─DynamicBasicBlock: 2-4                      [128, 64, 64, 64]         --\n",
       "│    │    └─Conv2d: 3-15                           [128, 64, 64, 64]         36,928\n",
       "│    │    └─BatchNorm2d: 3-16                      [128, 64, 64, 64]         128\n",
       "│    │    └─ReLU: 3-17                             [128, 64, 64, 64]         --\n",
       "│    │    └─Conv2d: 3-18                           [128, 64, 64, 64]         36,928\n",
       "│    │    └─BatchNorm2d: 3-19                      [128, 64, 64, 64]         128\n",
       "│    │    └─ReLU: 3-20                             [128, 64, 64, 64]         --\n",
       "├─Sequential: 1-6                                  [128, 128, 32, 32]        --\n",
       "│    └─DynamicBasicBlock: 2-5                      [128, 128, 32, 32]        --\n",
       "│    │    └─Sequential: 3-21                       [128, 128, 32, 32]        8,448\n",
       "│    │    └─Conv2d: 3-22                           [128, 128, 32, 32]        73,856\n",
       "│    │    └─BatchNorm2d: 3-23                      [128, 128, 32, 32]        256\n",
       "│    │    └─ReLU: 3-24                             [128, 128, 32, 32]        --\n",
       "│    │    └─Conv2d: 3-25                           [128, 128, 32, 32]        147,584\n",
       "│    │    └─BatchNorm2d: 3-26                      [128, 128, 32, 32]        256\n",
       "│    │    └─ReLU: 3-27                             [128, 128, 32, 32]        --\n",
       "│    └─DynamicBasicBlock: 2-6                      [128, 128, 32, 32]        --\n",
       "│    │    └─Conv2d: 3-28                           [128, 128, 32, 32]        147,584\n",
       "│    │    └─BatchNorm2d: 3-29                      [128, 128, 32, 32]        256\n",
       "│    │    └─ReLU: 3-30                             [128, 128, 32, 32]        --\n",
       "│    │    └─Conv2d: 3-31                           [128, 128, 32, 32]        147,584\n",
       "│    │    └─BatchNorm2d: 3-32                      [128, 128, 32, 32]        256\n",
       "│    │    └─ReLU: 3-33                             [128, 128, 32, 32]        --\n",
       "│    └─DynamicBasicBlock: 2-7                      [128, 128, 32, 32]        --\n",
       "│    │    └─Conv2d: 3-34                           [128, 128, 32, 32]        147,584\n",
       "│    │    └─BatchNorm2d: 3-35                      [128, 128, 32, 32]        256\n",
       "│    │    └─ReLU: 3-36                             [128, 128, 32, 32]        --\n",
       "│    │    └─Conv2d: 3-37                           [128, 128, 32, 32]        147,584\n",
       "│    │    └─BatchNorm2d: 3-38                      [128, 128, 32, 32]        256\n",
       "│    │    └─ReLU: 3-39                             [128, 128, 32, 32]        --\n",
       "│    └─DynamicBasicBlock: 2-8                      [128, 128, 32, 32]        --\n",
       "│    │    └─Conv2d: 3-40                           [128, 128, 32, 32]        147,584\n",
       "│    │    └─BatchNorm2d: 3-41                      [128, 128, 32, 32]        256\n",
       "│    │    └─ReLU: 3-42                             [128, 128, 32, 32]        --\n",
       "│    │    └─Conv2d: 3-43                           [128, 128, 32, 32]        147,584\n",
       "│    │    └─BatchNorm2d: 3-44                      [128, 128, 32, 32]        256\n",
       "│    │    └─ReLU: 3-45                             [128, 128, 32, 32]        --\n",
       "├─Sequential: 1-7                                  [128, 256, 16, 16]        --\n",
       "│    └─DynamicBasicBlock: 2-9                      [128, 256, 16, 16]        --\n",
       "│    │    └─Sequential: 3-46                       [128, 256, 16, 16]        33,280\n",
       "│    │    └─Conv2d: 3-47                           [128, 256, 16, 16]        295,168\n",
       "│    │    └─BatchNorm2d: 3-48                      [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-49                             [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-50                           [128, 256, 16, 16]        590,080\n",
       "│    │    └─BatchNorm2d: 3-51                      [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-52                             [128, 256, 16, 16]        --\n",
       "│    └─DynamicBasicBlock: 2-10                     [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-53                           [128, 256, 16, 16]        590,080\n",
       "│    │    └─BatchNorm2d: 3-54                      [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-55                             [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-56                           [128, 256, 16, 16]        590,080\n",
       "│    │    └─BatchNorm2d: 3-57                      [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-58                             [128, 256, 16, 16]        --\n",
       "│    └─DynamicBasicBlock: 2-11                     [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-59                           [128, 256, 16, 16]        590,080\n",
       "│    │    └─BatchNorm2d: 3-60                      [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-61                             [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-62                           [128, 256, 16, 16]        590,080\n",
       "│    │    └─BatchNorm2d: 3-63                      [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-64                             [128, 256, 16, 16]        --\n",
       "│    └─DynamicBasicBlock: 2-12                     [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-65                           [128, 256, 16, 16]        590,080\n",
       "│    │    └─BatchNorm2d: 3-66                      [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-67                             [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-68                           [128, 256, 16, 16]        590,080\n",
       "│    │    └─BatchNorm2d: 3-69                      [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-70                             [128, 256, 16, 16]        --\n",
       "│    └─DynamicBasicBlock: 2-13                     [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-71                           [128, 256, 16, 16]        590,080\n",
       "│    │    └─BatchNorm2d: 3-72                      [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-73                             [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-74                           [128, 256, 16, 16]        590,080\n",
       "│    │    └─BatchNorm2d: 3-75                      [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-76                             [128, 256, 16, 16]        --\n",
       "│    └─DynamicBasicBlock: 2-14                     [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-77                           [128, 256, 16, 16]        590,080\n",
       "│    │    └─BatchNorm2d: 3-78                      [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-79                             [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-80                           [128, 256, 16, 16]        590,080\n",
       "│    │    └─BatchNorm2d: 3-81                      [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-82                             [128, 256, 16, 16]        --\n",
       "├─Sequential: 1-8                                  [128, 512, 8, 8]          --\n",
       "│    └─DynamicBasicBlock: 2-15                     [128, 512, 8, 8]          --\n",
       "│    │    └─Sequential: 3-83                       [128, 512, 8, 8]          132,096\n",
       "│    │    └─Conv2d: 3-84                           [128, 512, 8, 8]          1,180,160\n",
       "│    │    └─BatchNorm2d: 3-85                      [128, 512, 8, 8]          1,024\n",
       "│    │    └─ReLU: 3-86                             [128, 512, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-87                           [128, 512, 8, 8]          2,359,808\n",
       "│    │    └─BatchNorm2d: 3-88                      [128, 512, 8, 8]          1,024\n",
       "│    │    └─ReLU: 3-89                             [128, 512, 8, 8]          --\n",
       "│    └─DynamicBasicBlock: 2-16                     [128, 512, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-90                           [128, 512, 8, 8]          2,359,808\n",
       "│    │    └─BatchNorm2d: 3-91                      [128, 512, 8, 8]          1,024\n",
       "│    │    └─ReLU: 3-92                             [128, 512, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-93                           [128, 512, 8, 8]          2,359,808\n",
       "│    │    └─BatchNorm2d: 3-94                      [128, 512, 8, 8]          1,024\n",
       "│    │    └─ReLU: 3-95                             [128, 512, 8, 8]          --\n",
       "│    └─DynamicBasicBlock: 2-17                     [128, 512, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-96                           [128, 512, 8, 8]          2,359,808\n",
       "│    │    └─BatchNorm2d: 3-97                      [128, 512, 8, 8]          1,024\n",
       "│    │    └─ReLU: 3-98                             [128, 512, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-99                           [128, 512, 8, 8]          2,359,808\n",
       "│    │    └─BatchNorm2d: 3-100                     [128, 512, 8, 8]          1,024\n",
       "│    │    └─ReLU: 3-101                            [128, 512, 8, 8]          --\n",
       "├─AdaptiveAvgPool2d: 1-9                           [128, 512, 1, 1]          --\n",
       "├─Linear: 1-10                                     [128, 50]                 25,650\n",
       "├─Softmax: 1-11                                    [128, 50]                 --\n",
       "====================================================================================================\n",
       "Total params: 21,545,671\n",
       "Trainable params: 21,545,671\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 554.45\n",
       "====================================================================================================\n",
       "Input size (MB): 25.17\n",
       "Forward/backward pass size (MB): 8388.81\n",
       "Params size (MB): 84.97\n",
       "Estimated Total Size (MB): 8498.94\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(dynamic_model, input_size=(128, 3, 128, 128))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet34 1 channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set length:63325, Validating Set length:450\n"
     ]
    }
   ],
   "source": [
    "train_data = CustomImageDataset(txt_file=\"train.txt\", img_dir=img_dir, transform=transform_train1, convert=\"L\")\n",
    "val_data = CustomImageDataset(txt_file=\"val.txt\", img_dir=img_dir, transform=transform_train1, convert=\"L\")\n",
    "test_data = CustomImageDataset(txt_file=\"test.txt\", img_dir=img_dir, transform=transform_test1, convert=\"L\")\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Training Set length:{len(train_data)}, Validating Set length:{len(val_data)}\")\n",
    "\n",
    "test_num = len(test_data)\n",
    "test_steps = len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch[1/10]: 100%|██████████| 495/495 [02:32<00:00,  3.24it/s]\n",
      "valid epoch[1/10]: 100%|██████████| 4/4 [00:00<00:00,  6.19it/s]\n",
      "\tTraining Loss: 3.903598 \tValidation Loss: 3.901765\n",
      "\tTrain Accuracy: 3.523d% (2231/63325)\tValdation Accuracy: 3.333d% (15/450) \n",
      "train epoch[2/10]: 100%|██████████| 495/495 [02:34<00:00,  3.21it/s]\n",
      "valid epoch[2/10]: 100%|██████████| 4/4 [00:00<00:00,  6.10it/s]\n",
      "\tTraining Loss: 3.892020 \tValidation Loss: 3.916335\n",
      "\tTrain Accuracy: 4.962d% (3142/63325)\tValdation Accuracy: 2.444d% (11/450) \n",
      "train epoch[3/10]: 100%|██████████| 495/495 [02:34<00:00,  3.21it/s]\n",
      "valid epoch[3/10]: 100%|██████████| 4/4 [00:00<00:00,  6.10it/s]\n",
      "\tTraining Loss: 3.881632 \tValidation Loss: 3.885682\n",
      "\tTrain Accuracy: 6.077d% (3848/63325)\tValdation Accuracy: 6.222d% (28/450) \n",
      "train epoch[4/10]: 100%|██████████| 495/495 [02:34<00:00,  3.21it/s]\n",
      "valid epoch[4/10]: 100%|██████████| 4/4 [00:00<00:00,  6.14it/s]\n",
      "\tTraining Loss: 3.873114 \tValidation Loss: 3.880978\n",
      "\tTrain Accuracy: 6.972d% (4415/63325)\tValdation Accuracy: 6.667d% (30/450) \n",
      "train epoch[5/10]: 100%|██████████| 495/495 [02:34<00:00,  3.21it/s]\n",
      "valid epoch[5/10]: 100%|██████████| 4/4 [00:00<00:00,  6.13it/s]\n",
      "\tTraining Loss: 3.865336 \tValidation Loss: 3.847461\n",
      "\tTrain Accuracy: 7.796d% (4937/63325)\tValdation Accuracy: 10.222d% (46/450) \n",
      "train epoch[6/10]: 100%|██████████| 495/495 [02:34<00:00,  3.19it/s]\n",
      "valid epoch[6/10]: 100%|██████████| 4/4 [00:00<00:00,  6.00it/s]\n",
      "\tTraining Loss: 3.857465 \tValidation Loss: 3.848281\n",
      "\tTrain Accuracy: 8.608d% (5451/63325)\tValdation Accuracy: 8.889d% (40/450) \n",
      "train epoch[7/10]: 100%|██████████| 495/495 [02:38<00:00,  3.12it/s]\n",
      "valid epoch[7/10]: 100%|██████████| 4/4 [00:00<00:00,  6.04it/s]\n",
      "\tTraining Loss: 3.849719 \tValidation Loss: 3.845942\n",
      "\tTrain Accuracy: 9.472d% (5998/63325)\tValdation Accuracy: 9.778d% (44/450) \n",
      "train epoch[8/10]: 100%|██████████| 495/495 [02:38<00:00,  3.12it/s]\n",
      "valid epoch[8/10]: 100%|██████████| 4/4 [00:00<00:00,  6.00it/s]\n",
      "\tTraining Loss: 3.843471 \tValidation Loss: 3.888423\n",
      "\tTrain Accuracy: 10.168d% (6439/63325)\tValdation Accuracy: 5.333d% (24/450) \n",
      "train epoch[9/10]: 100%|██████████| 495/495 [02:38<00:00,  3.13it/s]\n",
      "valid epoch[9/10]: 100%|██████████| 4/4 [00:00<00:00,  6.00it/s]\n",
      "\tTraining Loss: 3.835976 \tValidation Loss: 3.857894\n",
      "\tTrain Accuracy: 10.877d% (6888/63325)\tValdation Accuracy: 8.889d% (40/450) \n",
      "train epoch[10/10]: 100%|██████████| 495/495 [02:38<00:00,  3.13it/s]\n",
      "valid epoch[10/10]: 100%|██████████| 4/4 [00:00<00:00,  6.03it/s]\n",
      "\tTraining Loss: 3.828487 \tValidation Loss: 3.848612\n",
      "\tTrain Accuracy: 11.623d% (7360/63325)\tValdation Accuracy: 10.000d% (45/450) \n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "model1 = ResNet(BasicBlock, [3, 4, 6, 3], num_classes=50, channels=1)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model1.to(device)\n",
    "train_from_scratch(model1, train_loader, val_loader, epochs=num_epochs, learning_rate=lr, device=device, model_name=\"best_resnet34_1channels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: 100%|██████████| 4/4 [00:00<00:00,  6.18it/s]\n",
      "test_loss: 3.847  test_accuracy: 9.778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.8471043705940247, 9.777777777777779)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model = ResNet(BasicBlock, [3, 4, 6, 3], num_classes=50, channels=1).to(device)\n",
    "test_model.load_state_dict(torch.load(os.getcwd() + \"/\" + \"models/best_resnet34_1channels.pth\"))\n",
    "test_model.eval()\n",
    "test(test_model, test_loader=test_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNet                                   [128, 50]                 --\n",
       "├─Conv2d: 1-1                            [128, 64, 128, 128]       576\n",
       "├─BatchNorm2d: 1-2                       [128, 64, 128, 128]       128\n",
       "├─ReLU: 1-3                              [128, 64, 128, 128]       --\n",
       "├─MaxPool2d: 1-4                         [128, 64, 64, 64]         --\n",
       "├─Sequential: 1-5                        [128, 64, 64, 64]         --\n",
       "│    └─BasicBlock: 2-1                   [128, 64, 64, 64]         --\n",
       "│    │    └─Conv2d: 3-1                  [128, 64, 64, 64]         36,864\n",
       "│    │    └─BatchNorm2d: 3-2             [128, 64, 64, 64]         128\n",
       "│    │    └─ReLU: 3-3                    [128, 64, 64, 64]         --\n",
       "│    │    └─Conv2d: 3-4                  [128, 64, 64, 64]         36,864\n",
       "│    │    └─BatchNorm2d: 3-5             [128, 64, 64, 64]         128\n",
       "│    │    └─ReLU: 3-6                    [128, 64, 64, 64]         --\n",
       "│    └─BasicBlock: 2-2                   [128, 64, 64, 64]         --\n",
       "│    │    └─Conv2d: 3-7                  [128, 64, 64, 64]         36,864\n",
       "│    │    └─BatchNorm2d: 3-8             [128, 64, 64, 64]         128\n",
       "│    │    └─ReLU: 3-9                    [128, 64, 64, 64]         --\n",
       "│    │    └─Conv2d: 3-10                 [128, 64, 64, 64]         36,864\n",
       "│    │    └─BatchNorm2d: 3-11            [128, 64, 64, 64]         128\n",
       "│    │    └─ReLU: 3-12                   [128, 64, 64, 64]         --\n",
       "│    └─BasicBlock: 2-3                   [128, 64, 64, 64]         --\n",
       "│    │    └─Conv2d: 3-13                 [128, 64, 64, 64]         36,864\n",
       "│    │    └─BatchNorm2d: 3-14            [128, 64, 64, 64]         128\n",
       "│    │    └─ReLU: 3-15                   [128, 64, 64, 64]         --\n",
       "│    │    └─Conv2d: 3-16                 [128, 64, 64, 64]         36,864\n",
       "│    │    └─BatchNorm2d: 3-17            [128, 64, 64, 64]         128\n",
       "│    │    └─ReLU: 3-18                   [128, 64, 64, 64]         --\n",
       "├─Sequential: 1-6                        [128, 128, 32, 32]        --\n",
       "│    └─BasicBlock: 2-4                   [128, 128, 32, 32]        --\n",
       "│    │    └─Sequential: 3-19             [128, 128, 32, 32]        8,448\n",
       "│    │    └─Conv2d: 3-20                 [128, 128, 32, 32]        73,728\n",
       "│    │    └─BatchNorm2d: 3-21            [128, 128, 32, 32]        256\n",
       "│    │    └─ReLU: 3-22                   [128, 128, 32, 32]        --\n",
       "│    │    └─Conv2d: 3-23                 [128, 128, 32, 32]        147,456\n",
       "│    │    └─BatchNorm2d: 3-24            [128, 128, 32, 32]        256\n",
       "│    │    └─ReLU: 3-25                   [128, 128, 32, 32]        --\n",
       "│    └─BasicBlock: 2-5                   [128, 128, 32, 32]        --\n",
       "│    │    └─Conv2d: 3-26                 [128, 128, 32, 32]        147,456\n",
       "│    │    └─BatchNorm2d: 3-27            [128, 128, 32, 32]        256\n",
       "│    │    └─ReLU: 3-28                   [128, 128, 32, 32]        --\n",
       "│    │    └─Conv2d: 3-29                 [128, 128, 32, 32]        147,456\n",
       "│    │    └─BatchNorm2d: 3-30            [128, 128, 32, 32]        256\n",
       "│    │    └─ReLU: 3-31                   [128, 128, 32, 32]        --\n",
       "│    └─BasicBlock: 2-6                   [128, 128, 32, 32]        --\n",
       "│    │    └─Conv2d: 3-32                 [128, 128, 32, 32]        147,456\n",
       "│    │    └─BatchNorm2d: 3-33            [128, 128, 32, 32]        256\n",
       "│    │    └─ReLU: 3-34                   [128, 128, 32, 32]        --\n",
       "│    │    └─Conv2d: 3-35                 [128, 128, 32, 32]        147,456\n",
       "│    │    └─BatchNorm2d: 3-36            [128, 128, 32, 32]        256\n",
       "│    │    └─ReLU: 3-37                   [128, 128, 32, 32]        --\n",
       "│    └─BasicBlock: 2-7                   [128, 128, 32, 32]        --\n",
       "│    │    └─Conv2d: 3-38                 [128, 128, 32, 32]        147,456\n",
       "│    │    └─BatchNorm2d: 3-39            [128, 128, 32, 32]        256\n",
       "│    │    └─ReLU: 3-40                   [128, 128, 32, 32]        --\n",
       "│    │    └─Conv2d: 3-41                 [128, 128, 32, 32]        147,456\n",
       "│    │    └─BatchNorm2d: 3-42            [128, 128, 32, 32]        256\n",
       "│    │    └─ReLU: 3-43                   [128, 128, 32, 32]        --\n",
       "├─Sequential: 1-7                        [128, 256, 16, 16]        --\n",
       "│    └─BasicBlock: 2-8                   [128, 256, 16, 16]        --\n",
       "│    │    └─Sequential: 3-44             [128, 256, 16, 16]        33,280\n",
       "│    │    └─Conv2d: 3-45                 [128, 256, 16, 16]        294,912\n",
       "│    │    └─BatchNorm2d: 3-46            [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-47                   [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-48                 [128, 256, 16, 16]        589,824\n",
       "│    │    └─BatchNorm2d: 3-49            [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-50                   [128, 256, 16, 16]        --\n",
       "│    └─BasicBlock: 2-9                   [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-51                 [128, 256, 16, 16]        589,824\n",
       "│    │    └─BatchNorm2d: 3-52            [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-53                   [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-54                 [128, 256, 16, 16]        589,824\n",
       "│    │    └─BatchNorm2d: 3-55            [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-56                   [128, 256, 16, 16]        --\n",
       "│    └─BasicBlock: 2-10                  [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-57                 [128, 256, 16, 16]        589,824\n",
       "│    │    └─BatchNorm2d: 3-58            [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-59                   [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-60                 [128, 256, 16, 16]        589,824\n",
       "│    │    └─BatchNorm2d: 3-61            [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-62                   [128, 256, 16, 16]        --\n",
       "│    └─BasicBlock: 2-11                  [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-63                 [128, 256, 16, 16]        589,824\n",
       "│    │    └─BatchNorm2d: 3-64            [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-65                   [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-66                 [128, 256, 16, 16]        589,824\n",
       "│    │    └─BatchNorm2d: 3-67            [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-68                   [128, 256, 16, 16]        --\n",
       "│    └─BasicBlock: 2-12                  [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-69                 [128, 256, 16, 16]        589,824\n",
       "│    │    └─BatchNorm2d: 3-70            [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-71                   [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-72                 [128, 256, 16, 16]        589,824\n",
       "│    │    └─BatchNorm2d: 3-73            [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-74                   [128, 256, 16, 16]        --\n",
       "│    └─BasicBlock: 2-13                  [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-75                 [128, 256, 16, 16]        589,824\n",
       "│    │    └─BatchNorm2d: 3-76            [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-77                   [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-78                 [128, 256, 16, 16]        589,824\n",
       "│    │    └─BatchNorm2d: 3-79            [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-80                   [128, 256, 16, 16]        --\n",
       "├─Sequential: 1-8                        [128, 512, 8, 8]          --\n",
       "│    └─BasicBlock: 2-14                  [128, 512, 8, 8]          --\n",
       "│    │    └─Sequential: 3-81             [128, 512, 8, 8]          132,096\n",
       "│    │    └─Conv2d: 3-82                 [128, 512, 8, 8]          1,179,648\n",
       "│    │    └─BatchNorm2d: 3-83            [128, 512, 8, 8]          1,024\n",
       "│    │    └─ReLU: 3-84                   [128, 512, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-85                 [128, 512, 8, 8]          2,359,296\n",
       "│    │    └─BatchNorm2d: 3-86            [128, 512, 8, 8]          1,024\n",
       "│    │    └─ReLU: 3-87                   [128, 512, 8, 8]          --\n",
       "│    └─BasicBlock: 2-15                  [128, 512, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-88                 [128, 512, 8, 8]          2,359,296\n",
       "│    │    └─BatchNorm2d: 3-89            [128, 512, 8, 8]          1,024\n",
       "│    │    └─ReLU: 3-90                   [128, 512, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-91                 [128, 512, 8, 8]          2,359,296\n",
       "│    │    └─BatchNorm2d: 3-92            [128, 512, 8, 8]          1,024\n",
       "│    │    └─ReLU: 3-93                   [128, 512, 8, 8]          --\n",
       "│    └─BasicBlock: 2-16                  [128, 512, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-94                 [128, 512, 8, 8]          2,359,296\n",
       "│    │    └─BatchNorm2d: 3-95            [128, 512, 8, 8]          1,024\n",
       "│    │    └─ReLU: 3-96                   [128, 512, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-97                 [128, 512, 8, 8]          2,359,296\n",
       "│    │    └─BatchNorm2d: 3-98            [128, 512, 8, 8]          1,024\n",
       "│    │    └─ReLU: 3-99                   [128, 512, 8, 8]          --\n",
       "├─AdaptiveAvgPool2d: 1-9                 [128, 512, 1, 1]          --\n",
       "├─Linear: 1-10                           [128, 50]                 25,650\n",
       "├─Softmax: 1-11                          [128, 50]                 --\n",
       "==========================================================================================\n",
       "Total params: 21,301,490\n",
       "Trainable params: 21,301,490\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 593.92\n",
       "==========================================================================================\n",
       "Input size (MB): 8.39\n",
       "Forward/backward pass size (MB): 9999.27\n",
       "Params size (MB): 85.21\n",
       "Estimated Total Size (MB): 10092.87\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model1, input_size=(128, 1, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  21.3 M, 100.000% Params, 4.66 GMac, 99.877% MACs, \n",
      "  (conv1): Conv2d(576, 0.003% Params, 9.44 MMac, 0.202% MACs, 1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, 0.001% Params, 2.1 MMac, 0.045% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(0, 0.000% Params, 1.05 MMac, 0.022% MACs, inplace=True)\n",
      "  (maxpool): MaxPool2d(0, 0.000% Params, 1.05 MMac, 0.022% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    221.95 k, 1.042% Params, 910.69 MMac, 19.538% MACs, \n",
      "    (0): BasicBlock(\n",
      "      73.98 k, 0.347% Params, 303.56 MMac, 6.513% MACs, \n",
      "      (conv1): Conv2d(36.86 k, 0.173% Params, 150.99 MMac, 3.239% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, 0.001% Params, 524.29 KMac, 0.011% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 524.29 KMac, 0.011% MACs, )\n",
      "      (conv2): Conv2d(36.86 k, 0.173% Params, 150.99 MMac, 3.239% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, 0.001% Params, 524.29 KMac, 0.011% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      73.98 k, 0.347% Params, 303.56 MMac, 6.513% MACs, \n",
      "      (conv1): Conv2d(36.86 k, 0.173% Params, 150.99 MMac, 3.239% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, 0.001% Params, 524.29 KMac, 0.011% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 524.29 KMac, 0.011% MACs, )\n",
      "      (conv2): Conv2d(36.86 k, 0.173% Params, 150.99 MMac, 3.239% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, 0.001% Params, 524.29 KMac, 0.011% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      73.98 k, 0.347% Params, 303.56 MMac, 6.513% MACs, \n",
      "      (conv1): Conv2d(36.86 k, 0.173% Params, 150.99 MMac, 3.239% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, 0.001% Params, 524.29 KMac, 0.011% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 524.29 KMac, 0.011% MACs, )\n",
      "      (conv2): Conv2d(36.86 k, 0.173% Params, 150.99 MMac, 3.239% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, 0.001% Params, 524.29 KMac, 0.011% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    1.12 M, 5.241% Params, 1.14 GMac, 24.549% MACs, \n",
      "    (0): BasicBlock(\n",
      "      230.14 k, 1.080% Params, 235.93 MMac, 5.062% MACs, \n",
      "      (conv1): Conv2d(73.73 k, 0.346% Params, 75.5 MMac, 1.620% MACs, 64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, 0.001% Params, 262.14 KMac, 0.006% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 262.14 KMac, 0.006% MACs, )\n",
      "      (conv2): Conv2d(147.46 k, 0.692% Params, 150.99 MMac, 3.239% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, 0.001% Params, 262.14 KMac, 0.006% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        8.45 k, 0.040% Params, 8.65 MMac, 0.186% MACs, \n",
      "        (0): Conv2d(8.19 k, 0.038% Params, 8.39 MMac, 0.180% MACs, 64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, 0.001% Params, 262.14 KMac, 0.006% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      295.42 k, 1.387% Params, 302.78 MMac, 6.496% MACs, \n",
      "      (conv1): Conv2d(147.46 k, 0.692% Params, 150.99 MMac, 3.239% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, 0.001% Params, 262.14 KMac, 0.006% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 262.14 KMac, 0.006% MACs, )\n",
      "      (conv2): Conv2d(147.46 k, 0.692% Params, 150.99 MMac, 3.239% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, 0.001% Params, 262.14 KMac, 0.006% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      295.42 k, 1.387% Params, 302.78 MMac, 6.496% MACs, \n",
      "      (conv1): Conv2d(147.46 k, 0.692% Params, 150.99 MMac, 3.239% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, 0.001% Params, 262.14 KMac, 0.006% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 262.14 KMac, 0.006% MACs, )\n",
      "      (conv2): Conv2d(147.46 k, 0.692% Params, 150.99 MMac, 3.239% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, 0.001% Params, 262.14 KMac, 0.006% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      295.42 k, 1.387% Params, 302.78 MMac, 6.496% MACs, \n",
      "      (conv1): Conv2d(147.46 k, 0.692% Params, 150.99 MMac, 3.239% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, 0.001% Params, 262.14 KMac, 0.006% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 262.14 KMac, 0.006% MACs, )\n",
      "      (conv2): Conv2d(147.46 k, 0.692% Params, 150.99 MMac, 3.239% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, 0.001% Params, 262.14 KMac, 0.006% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    6.82 M, 32.028% Params, 1.75 GMac, 37.486% MACs, \n",
      "    (0): BasicBlock(\n",
      "      919.04 k, 4.314% Params, 235.41 MMac, 5.050% MACs, \n",
      "      (conv1): Conv2d(294.91 k, 1.384% Params, 75.5 MMac, 1.620% MACs, 128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 131.07 KMac, 0.003% MACs, )\n",
      "      (conv2): Conv2d(589.82 k, 2.769% Params, 150.99 MMac, 3.239% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        33.28 k, 0.156% Params, 8.52 MMac, 0.183% MACs, \n",
      "        (0): Conv2d(32.77 k, 0.154% Params, 8.39 MMac, 0.180% MACs, 128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      1.18 M, 5.543% Params, 302.38 MMac, 6.487% MACs, \n",
      "      (conv1): Conv2d(589.82 k, 2.769% Params, 150.99 MMac, 3.239% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 131.07 KMac, 0.003% MACs, )\n",
      "      (conv2): Conv2d(589.82 k, 2.769% Params, 150.99 MMac, 3.239% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      1.18 M, 5.543% Params, 302.38 MMac, 6.487% MACs, \n",
      "      (conv1): Conv2d(589.82 k, 2.769% Params, 150.99 MMac, 3.239% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 131.07 KMac, 0.003% MACs, )\n",
      "      (conv2): Conv2d(589.82 k, 2.769% Params, 150.99 MMac, 3.239% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      1.18 M, 5.543% Params, 302.38 MMac, 6.487% MACs, \n",
      "      (conv1): Conv2d(589.82 k, 2.769% Params, 150.99 MMac, 3.239% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 131.07 KMac, 0.003% MACs, )\n",
      "      (conv2): Conv2d(589.82 k, 2.769% Params, 150.99 MMac, 3.239% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): BasicBlock(\n",
      "      1.18 M, 5.543% Params, 302.38 MMac, 6.487% MACs, \n",
      "      (conv1): Conv2d(589.82 k, 2.769% Params, 150.99 MMac, 3.239% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 131.07 KMac, 0.003% MACs, )\n",
      "      (conv2): Conv2d(589.82 k, 2.769% Params, 150.99 MMac, 3.239% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      1.18 M, 5.543% Params, 302.38 MMac, 6.487% MACs, \n",
      "      (conv1): Conv2d(589.82 k, 2.769% Params, 150.99 MMac, 3.239% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 131.07 KMac, 0.003% MACs, )\n",
      "      (conv2): Conv2d(589.82 k, 2.769% Params, 150.99 MMac, 3.239% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    13.11 M, 61.565% Params, 839.52 MMac, 18.011% MACs, \n",
      "    (0): BasicBlock(\n",
      "      3.67 M, 17.243% Params, 235.14 MMac, 5.045% MACs, \n",
      "      (conv1): Conv2d(1.18 M, 5.538% Params, 75.5 MMac, 1.620% MACs, 256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1.02 k, 0.005% Params, 65.54 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 65.54 KMac, 0.001% MACs, )\n",
      "      (conv2): Conv2d(2.36 M, 11.076% Params, 150.99 MMac, 3.239% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1.02 k, 0.005% Params, 65.54 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        132.1 k, 0.620% Params, 8.45 MMac, 0.181% MACs, \n",
      "        (0): Conv2d(131.07 k, 0.615% Params, 8.39 MMac, 0.180% MACs, 256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1.02 k, 0.005% Params, 65.54 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      4.72 M, 22.161% Params, 302.19 MMac, 6.483% MACs, \n",
      "      (conv1): Conv2d(2.36 M, 11.076% Params, 150.99 MMac, 3.239% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1.02 k, 0.005% Params, 65.54 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 65.54 KMac, 0.001% MACs, )\n",
      "      (conv2): Conv2d(2.36 M, 11.076% Params, 150.99 MMac, 3.239% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1.02 k, 0.005% Params, 65.54 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      4.72 M, 22.161% Params, 302.19 MMac, 6.483% MACs, \n",
      "      (conv1): Conv2d(2.36 M, 11.076% Params, 150.99 MMac, 3.239% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1.02 k, 0.005% Params, 65.54 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 65.54 KMac, 0.001% MACs, )\n",
      "      (conv2): Conv2d(2.36 M, 11.076% Params, 150.99 MMac, 3.239% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1.02 k, 0.005% Params, 65.54 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 32.77 KMac, 0.001% MACs, output_size=(1, 1))\n",
      "  (fc): Linear(25.65 k, 0.120% Params, 25.65 KMac, 0.001% MACs, in_features=512, out_features=50, bias=True)\n",
      "  (softmax): Softmax(0, 0.000% Params, 0.0 Mac, 0.000% MACs, dim=1)\n",
      ")\n",
      "FLOPS: 4.66 GMac\n",
      "Parameters: 21.3 M\n"
     ]
    }
   ],
   "source": [
    "flops, params = get_model_complexity_info(model1, (1, 128, 128), as_strings=True, print_per_layer_stat=True)\n",
    "\n",
    "print(f\"FLOPS: {flops}\")\n",
    "print(f\"Parameters: {params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DynamicResnet 1 channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch[1/10]: 100%|██████████| 495/495 [02:41<00:00,  3.06it/s]\n",
      "valid epoch[1/10]: 100%|██████████| 4/4 [00:00<00:00,  5.80it/s]\n",
      "\tTraining Loss: 3.893568 \tValidation Loss: 3.902633\n",
      "\tTrain Accuracy: 4.698d% (2975/63325)\tValdation Accuracy: 3.778d% (17/450) \n",
      "train epoch[2/10]: 100%|██████████| 495/495 [02:41<00:00,  3.07it/s]\n",
      "valid epoch[2/10]: 100%|██████████| 4/4 [00:00<00:00,  5.87it/s]\n",
      "\tTraining Loss: 3.876602 \tValidation Loss: 3.880385\n",
      "\tTrain Accuracy: 6.685d% (4233/63325)\tValdation Accuracy: 6.000d% (27/450) \n",
      "train epoch[3/10]: 100%|██████████| 495/495 [02:41<00:00,  3.07it/s]\n",
      "valid epoch[3/10]: 100%|██████████| 4/4 [00:00<00:00,  5.81it/s]\n",
      "\tTraining Loss: 3.868246 \tValidation Loss: 3.870107\n",
      "\tTrain Accuracy: 7.468d% (4729/63325)\tValdation Accuracy: 7.111d% (32/450) \n",
      "train epoch[4/10]: 100%|██████████| 495/495 [02:41<00:00,  3.07it/s]\n",
      "valid epoch[4/10]: 100%|██████████| 4/4 [00:00<00:00,  5.85it/s]\n",
      "\tTraining Loss: 3.862120 \tValidation Loss: 3.859920\n",
      "\tTrain Accuracy: 8.158d% (5166/63325)\tValdation Accuracy: 8.444d% (38/450) \n",
      "train epoch[5/10]: 100%|██████████| 495/495 [02:41<00:00,  3.07it/s]\n",
      "valid epoch[5/10]: 100%|██████████| 4/4 [00:00<00:00,  5.84it/s]\n",
      "\tTraining Loss: 3.854429 \tValidation Loss: 3.851288\n",
      "\tTrain Accuracy: 8.916d% (5646/63325)\tValdation Accuracy: 9.333d% (42/450) \n",
      "train epoch[6/10]: 100%|██████████| 495/495 [02:41<00:00,  3.06it/s]\n",
      "valid epoch[6/10]: 100%|██████████| 4/4 [00:00<00:00,  5.84it/s]\n",
      "\tTraining Loss: 3.845488 \tValidation Loss: 3.862571\n",
      "\tTrain Accuracy: 9.786d% (6197/63325)\tValdation Accuracy: 8.222d% (37/450) \n",
      "train epoch[7/10]: 100%|██████████| 495/495 [02:41<00:00,  3.06it/s]\n",
      "valid epoch[7/10]: 100%|██████████| 4/4 [00:00<00:00,  5.86it/s]\n",
      "\tTraining Loss: 3.836237 \tValidation Loss: 3.830699\n",
      "\tTrain Accuracy: 10.784d% (6829/63325)\tValdation Accuracy: 11.778d% (53/450) \n",
      "train epoch[8/10]: 100%|██████████| 495/495 [02:41<00:00,  3.06it/s]\n",
      "valid epoch[8/10]: 100%|██████████| 4/4 [00:00<00:00,  5.88it/s]\n",
      "\tTraining Loss: 3.832397 \tValidation Loss: 3.867408\n",
      "\tTrain Accuracy: 11.204d% (7095/63325)\tValdation Accuracy: 7.333d% (33/450) \n",
      "train epoch[9/10]: 100%|██████████| 495/495 [02:41<00:00,  3.06it/s]\n",
      "valid epoch[9/10]: 100%|██████████| 4/4 [00:00<00:00,  5.87it/s]\n",
      "\tTraining Loss: 3.825681 \tValidation Loss: 3.834957\n",
      "\tTrain Accuracy: 11.867d% (7515/63325)\tValdation Accuracy: 11.111d% (50/450) \n",
      "train epoch[10/10]: 100%|██████████| 495/495 [02:41<00:00,  3.06it/s]\n",
      "valid epoch[10/10]: 100%|██████████| 4/4 [00:00<00:00,  5.80it/s]\n",
      "\tTraining Loss: 3.814800 \tValidation Loss: 3.831346\n",
      "\tTrain Accuracy: 13.050d% (8264/63325)\tValdation Accuracy: 11.556d% (52/450) \n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "dynamic_model1 = DynamicResNet(DynamicBasicBlock, [3, 4, 6, 3], num_classes=50, channels=1)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dynamic_model1.to(device)\n",
    "train_from_scratch(dynamic_model1, train_loader, val_loader, epochs=num_epochs, learning_rate=lr, device=device, model_name=\"best_dynamic_resnet34_1channels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: 100%|██████████| 4/4 [00:00<00:00,  5.83it/s]\n",
      "test_loss: 3.805  test_accuracy: 13.111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.804931402206421, 13.111111111111112)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model = DynamicResNet(DynamicBasicBlock, [3, 4, 6, 3], num_classes=50, channels=1).to(device)\n",
    "test_model.load_state_dict(torch.load(os.getcwd() + \"/\" + \"models/best_dynamic_resnet34_1channels.pth\"))\n",
    "test_model.eval()\n",
    "test(test_model, test_loader=test_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DynamicResNet(\n",
      "  21.24 M, 98.618% Params, 4.35 GMac, 99.849% MACs, \n",
      "  (conv1): DynamicConv(\n",
      "    5, 0.000% Params, 16.39 KMac, 0.000% MACs, \n",
      "    (attention): attention2d(\n",
      "      5, 0.000% Params, 16.39 KMac, 0.000% MACs, \n",
      "      (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 16.38 KMac, 0.000% MACs, output_size=1)\n",
      "      (cal): Sequential(\n",
      "        5, 0.000% Params, 6.0 Mac, 0.000% MACs, \n",
      "        (0): Conv2d(1, 0.000% Params, 1.0 Mac, 0.000% MACs, 1, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): ReLU(0, 0.000% Params, 1.0 Mac, 0.000% MACs, )\n",
      "        (2): Conv2d(4, 0.000% Params, 4.0 Mac, 0.000% MACs, 1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (bn1): BatchNorm2d(128, 0.001% Params, 2.1 MMac, 0.048% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(0, 0.000% Params, 1.05 MMac, 0.024% MACs, inplace=True)\n",
      "  (maxpool): MaxPool2d(0, 0.000% Params, 1.05 MMac, 0.024% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    157.18 k, 0.730% Params, 610.28 MMac, 14.016% MACs, \n",
      "    (0): DynamicBasicBlock(\n",
      "      8.96 k, 0.042% Params, 2.11 MMac, 0.048% MACs, \n",
      "      (conv1): DynamicConv(\n",
      "        4.35 k, 0.020% Params, 266.56 KMac, 0.006% MACs, \n",
      "        (attention): attention2d(\n",
      "          4.35 k, 0.020% Params, 266.56 KMac, 0.006% MACs, \n",
      "          (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 262.14 KMac, 0.006% MACs, output_size=1)\n",
      "          (cal): Sequential(\n",
      "            4.35 k, 0.020% Params, 4.42 KMac, 0.000% MACs, \n",
      "            (0): Conv2d(4.1 k, 0.019% Params, 4.1 KMac, 0.000% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): ReLU(0, 0.000% Params, 64.0 Mac, 0.000% MACs, )\n",
      "            (2): Conv2d(256, 0.001% Params, 256.0 Mac, 0.000% MACs, 64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv2): DynamicConv(\n",
      "        4.35 k, 0.020% Params, 266.56 KMac, 0.006% MACs, \n",
      "        (attention): attention2d(\n",
      "          4.35 k, 0.020% Params, 266.56 KMac, 0.006% MACs, \n",
      "          (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 262.14 KMac, 0.006% MACs, output_size=1)\n",
      "          (cal): Sequential(\n",
      "            4.35 k, 0.020% Params, 4.42 KMac, 0.000% MACs, \n",
      "            (0): Conv2d(4.1 k, 0.019% Params, 4.1 KMac, 0.000% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): ReLU(0, 0.000% Params, 64.0 Mac, 0.000% MACs, )\n",
      "            (2): Conv2d(256, 0.001% Params, 256.0 Mac, 0.000% MACs, 64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (bn1): BatchNorm2d(128, 0.001% Params, 524.29 KMac, 0.012% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 524.29 KMac, 0.012% MACs, )\n",
      "      (bn2): BatchNorm2d(128, 0.001% Params, 524.29 KMac, 0.012% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): DynamicBasicBlock(\n",
      "      74.11 k, 0.344% Params, 304.09 MMac, 6.984% MACs, \n",
      "      (conv1): Conv2d(36.93 k, 0.171% Params, 151.26 MMac, 3.474% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(36.93 k, 0.171% Params, 151.26 MMac, 3.474% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, 0.001% Params, 524.29 KMac, 0.012% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 524.29 KMac, 0.012% MACs, )\n",
      "      (bn2): BatchNorm2d(128, 0.001% Params, 524.29 KMac, 0.012% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): DynamicBasicBlock(\n",
      "      74.11 k, 0.344% Params, 304.09 MMac, 6.984% MACs, \n",
      "      (conv1): Conv2d(36.93 k, 0.171% Params, 151.26 MMac, 3.474% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(36.93 k, 0.171% Params, 151.26 MMac, 3.474% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, 0.001% Params, 524.29 KMac, 0.012% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 524.29 KMac, 0.012% MACs, )\n",
      "      (bn2): BatchNorm2d(128, 0.001% Params, 524.29 KMac, 0.012% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    1.12 M, 5.187% Params, 1.15 GMac, 26.303% MACs, \n",
      "    (0): DynamicBasicBlock(\n",
      "      230.4 k, 1.070% Params, 236.19 MMac, 5.424% MACs, \n",
      "      (conv1): Conv2d(73.86 k, 0.343% Params, 75.63 MMac, 1.737% MACs, 64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (conv2): Conv2d(147.58 k, 0.685% Params, 151.13 MMac, 3.471% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, 0.001% Params, 262.14 KMac, 0.006% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 262.14 KMac, 0.006% MACs, )\n",
      "      (bn2): BatchNorm2d(256, 0.001% Params, 262.14 KMac, 0.006% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        8.45 k, 0.039% Params, 8.65 MMac, 0.199% MACs, \n",
      "        (0): Conv2d(8.19 k, 0.038% Params, 8.39 MMac, 0.193% MACs, 64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, 0.001% Params, 262.14 KMac, 0.006% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): DynamicBasicBlock(\n",
      "      295.68 k, 1.373% Params, 303.04 MMac, 6.960% MACs, \n",
      "      (conv1): Conv2d(147.58 k, 0.685% Params, 151.13 MMac, 3.471% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(147.58 k, 0.685% Params, 151.13 MMac, 3.471% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, 0.001% Params, 262.14 KMac, 0.006% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 262.14 KMac, 0.006% MACs, )\n",
      "      (bn2): BatchNorm2d(256, 0.001% Params, 262.14 KMac, 0.006% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): DynamicBasicBlock(\n",
      "      295.68 k, 1.373% Params, 303.04 MMac, 6.960% MACs, \n",
      "      (conv1): Conv2d(147.58 k, 0.685% Params, 151.13 MMac, 3.471% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(147.58 k, 0.685% Params, 151.13 MMac, 3.471% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, 0.001% Params, 262.14 KMac, 0.006% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 262.14 KMac, 0.006% MACs, )\n",
      "      (bn2): BatchNorm2d(256, 0.001% Params, 262.14 KMac, 0.006% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): DynamicBasicBlock(\n",
      "      295.68 k, 1.373% Params, 303.04 MMac, 6.960% MACs, \n",
      "      (conv1): Conv2d(147.58 k, 0.685% Params, 151.13 MMac, 3.471% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(147.58 k, 0.685% Params, 151.13 MMac, 3.471% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, 0.001% Params, 262.14 KMac, 0.006% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 262.14 KMac, 0.006% MACs, )\n",
      "      (bn2): BatchNorm2d(256, 0.001% Params, 262.14 KMac, 0.006% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    6.83 M, 31.686% Params, 1.75 GMac, 40.147% MACs, \n",
      "    (0): DynamicBasicBlock(\n",
      "      919.55 k, 4.269% Params, 235.54 MMac, 5.409% MACs, \n",
      "      (conv1): Conv2d(295.17 k, 1.370% Params, 75.56 MMac, 1.735% MACs, 128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (conv2): Conv2d(590.08 k, 2.739% Params, 151.06 MMac, 3.469% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 131.07 KMac, 0.003% MACs, )\n",
      "      (bn2): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        33.28 k, 0.154% Params, 8.52 MMac, 0.196% MACs, \n",
      "        (0): Conv2d(32.77 k, 0.152% Params, 8.39 MMac, 0.193% MACs, 128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): DynamicBasicBlock(\n",
      "      1.18 M, 5.483% Params, 302.51 MMac, 6.948% MACs, \n",
      "      (conv1): Conv2d(590.08 k, 2.739% Params, 151.06 MMac, 3.469% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(590.08 k, 2.739% Params, 151.06 MMac, 3.469% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 131.07 KMac, 0.003% MACs, )\n",
      "      (bn2): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): DynamicBasicBlock(\n",
      "      1.18 M, 5.483% Params, 302.51 MMac, 6.948% MACs, \n",
      "      (conv1): Conv2d(590.08 k, 2.739% Params, 151.06 MMac, 3.469% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(590.08 k, 2.739% Params, 151.06 MMac, 3.469% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 131.07 KMac, 0.003% MACs, )\n",
      "      (bn2): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): DynamicBasicBlock(\n",
      "      1.18 M, 5.483% Params, 302.51 MMac, 6.948% MACs, \n",
      "      (conv1): Conv2d(590.08 k, 2.739% Params, 151.06 MMac, 3.469% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(590.08 k, 2.739% Params, 151.06 MMac, 3.469% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 131.07 KMac, 0.003% MACs, )\n",
      "      (bn2): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): DynamicBasicBlock(\n",
      "      1.18 M, 5.483% Params, 302.51 MMac, 6.948% MACs, \n",
      "      (conv1): Conv2d(590.08 k, 2.739% Params, 151.06 MMac, 3.469% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(590.08 k, 2.739% Params, 151.06 MMac, 3.469% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 131.07 KMac, 0.003% MACs, )\n",
      "      (bn2): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): DynamicBasicBlock(\n",
      "      1.18 M, 5.483% Params, 302.51 MMac, 6.948% MACs, \n",
      "      (conv1): Conv2d(590.08 k, 2.739% Params, 151.06 MMac, 3.469% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(590.08 k, 2.739% Params, 151.06 MMac, 3.469% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 131.07 KMac, 0.003% MACs, )\n",
      "      (bn2): BatchNorm2d(512, 0.002% Params, 131.07 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    13.12 M, 60.895% Params, 839.71 MMac, 19.285% MACs, \n",
      "    (0): DynamicBasicBlock(\n",
      "      3.67 M, 17.056% Params, 235.21 MMac, 5.402% MACs, \n",
      "      (conv1): Conv2d(1.18 M, 5.479% Params, 75.53 MMac, 1.735% MACs, 256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (conv2): Conv2d(2.36 M, 10.955% Params, 151.03 MMac, 3.469% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(1.02 k, 0.005% Params, 65.54 KMac, 0.002% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 65.54 KMac, 0.002% MACs, )\n",
      "      (bn2): BatchNorm2d(1.02 k, 0.005% Params, 65.54 KMac, 0.002% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        132.1 k, 0.613% Params, 8.45 MMac, 0.194% MACs, \n",
      "        (0): Conv2d(131.07 k, 0.608% Params, 8.39 MMac, 0.193% MACs, 256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1.02 k, 0.005% Params, 65.54 KMac, 0.002% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): DynamicBasicBlock(\n",
      "      4.72 M, 21.919% Params, 302.25 MMac, 6.942% MACs, \n",
      "      (conv1): Conv2d(2.36 M, 10.955% Params, 151.03 MMac, 3.469% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(2.36 M, 10.955% Params, 151.03 MMac, 3.469% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(1.02 k, 0.005% Params, 65.54 KMac, 0.002% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 65.54 KMac, 0.002% MACs, )\n",
      "      (bn2): BatchNorm2d(1.02 k, 0.005% Params, 65.54 KMac, 0.002% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): DynamicBasicBlock(\n",
      "      4.72 M, 21.919% Params, 302.25 MMac, 6.942% MACs, \n",
      "      (conv1): Conv2d(2.36 M, 10.955% Params, 151.03 MMac, 3.469% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(2.36 M, 10.955% Params, 151.03 MMac, 3.469% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(1.02 k, 0.005% Params, 65.54 KMac, 0.002% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 65.54 KMac, 0.002% MACs, )\n",
      "      (bn2): BatchNorm2d(1.02 k, 0.005% Params, 65.54 KMac, 0.002% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 32.77 KMac, 0.001% MACs, output_size=(1, 1))\n",
      "  (fc): Linear(25.65 k, 0.119% Params, 25.65 KMac, 0.001% MACs, in_features=512, out_features=50, bias=True)\n",
      "  (softmax): Softmax(0, 0.000% Params, 0.0 Mac, 0.000% MACs, dim=1)\n",
      ")\n",
      "FLOPS: 4.35 GMac\n",
      "Parameters: 21.54 M\n"
     ]
    }
   ],
   "source": [
    "flops, params = get_model_complexity_info(dynamic_model1, (1, 128, 128), as_strings=True, print_per_layer_stat=True)\n",
    "\n",
    "print(f\"FLOPS: {flops}\")\n",
    "print(f\"Parameters: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "DynamicResNet                                      [128, 50]                 --\n",
       "├─DynamicConv: 1-1                                 [128, 64, 128, 128]       2,304\n",
       "│    └─attention2d: 2-1                            [128, 4]                  --\n",
       "│    │    └─AdaptiveAvgPool2d: 3-1                 [128, 1, 1, 1]            --\n",
       "│    │    └─Sequential: 3-2                        [128, 4, 1, 1]            5\n",
       "├─BatchNorm2d: 1-2                                 [128, 64, 128, 128]       128\n",
       "├─ReLU: 1-3                                        [128, 64, 128, 128]       --\n",
       "├─MaxPool2d: 1-4                                   [128, 64, 64, 64]         --\n",
       "├─Sequential: 1-5                                  [128, 64, 64, 64]         --\n",
       "│    └─DynamicBasicBlock: 2-2                      [128, 64, 64, 64]         --\n",
       "│    │    └─DynamicConv: 3-3                       [128, 64, 64, 64]         152,064\n",
       "│    │    └─BatchNorm2d: 3-4                       [128, 64, 64, 64]         128\n",
       "│    │    └─ReLU: 3-5                              [128, 64, 64, 64]         --\n",
       "│    │    └─DynamicConv: 3-6                       [128, 64, 64, 64]         152,064\n",
       "│    │    └─BatchNorm2d: 3-7                       [128, 64, 64, 64]         128\n",
       "│    │    └─ReLU: 3-8                              [128, 64, 64, 64]         --\n",
       "│    └─DynamicBasicBlock: 2-3                      [128, 64, 64, 64]         --\n",
       "│    │    └─Conv2d: 3-9                            [128, 64, 64, 64]         36,928\n",
       "│    │    └─BatchNorm2d: 3-10                      [128, 64, 64, 64]         128\n",
       "│    │    └─ReLU: 3-11                             [128, 64, 64, 64]         --\n",
       "│    │    └─Conv2d: 3-12                           [128, 64, 64, 64]         36,928\n",
       "│    │    └─BatchNorm2d: 3-13                      [128, 64, 64, 64]         128\n",
       "│    │    └─ReLU: 3-14                             [128, 64, 64, 64]         --\n",
       "│    └─DynamicBasicBlock: 2-4                      [128, 64, 64, 64]         --\n",
       "│    │    └─Conv2d: 3-15                           [128, 64, 64, 64]         36,928\n",
       "│    │    └─BatchNorm2d: 3-16                      [128, 64, 64, 64]         128\n",
       "│    │    └─ReLU: 3-17                             [128, 64, 64, 64]         --\n",
       "│    │    └─Conv2d: 3-18                           [128, 64, 64, 64]         36,928\n",
       "│    │    └─BatchNorm2d: 3-19                      [128, 64, 64, 64]         128\n",
       "│    │    └─ReLU: 3-20                             [128, 64, 64, 64]         --\n",
       "├─Sequential: 1-6                                  [128, 128, 32, 32]        --\n",
       "│    └─DynamicBasicBlock: 2-5                      [128, 128, 32, 32]        --\n",
       "│    │    └─Sequential: 3-21                       [128, 128, 32, 32]        8,448\n",
       "│    │    └─Conv2d: 3-22                           [128, 128, 32, 32]        73,856\n",
       "│    │    └─BatchNorm2d: 3-23                      [128, 128, 32, 32]        256\n",
       "│    │    └─ReLU: 3-24                             [128, 128, 32, 32]        --\n",
       "│    │    └─Conv2d: 3-25                           [128, 128, 32, 32]        147,584\n",
       "│    │    └─BatchNorm2d: 3-26                      [128, 128, 32, 32]        256\n",
       "│    │    └─ReLU: 3-27                             [128, 128, 32, 32]        --\n",
       "│    └─DynamicBasicBlock: 2-6                      [128, 128, 32, 32]        --\n",
       "│    │    └─Conv2d: 3-28                           [128, 128, 32, 32]        147,584\n",
       "│    │    └─BatchNorm2d: 3-29                      [128, 128, 32, 32]        256\n",
       "│    │    └─ReLU: 3-30                             [128, 128, 32, 32]        --\n",
       "│    │    └─Conv2d: 3-31                           [128, 128, 32, 32]        147,584\n",
       "│    │    └─BatchNorm2d: 3-32                      [128, 128, 32, 32]        256\n",
       "│    │    └─ReLU: 3-33                             [128, 128, 32, 32]        --\n",
       "│    └─DynamicBasicBlock: 2-7                      [128, 128, 32, 32]        --\n",
       "│    │    └─Conv2d: 3-34                           [128, 128, 32, 32]        147,584\n",
       "│    │    └─BatchNorm2d: 3-35                      [128, 128, 32, 32]        256\n",
       "│    │    └─ReLU: 3-36                             [128, 128, 32, 32]        --\n",
       "│    │    └─Conv2d: 3-37                           [128, 128, 32, 32]        147,584\n",
       "│    │    └─BatchNorm2d: 3-38                      [128, 128, 32, 32]        256\n",
       "│    │    └─ReLU: 3-39                             [128, 128, 32, 32]        --\n",
       "│    └─DynamicBasicBlock: 2-8                      [128, 128, 32, 32]        --\n",
       "│    │    └─Conv2d: 3-40                           [128, 128, 32, 32]        147,584\n",
       "│    │    └─BatchNorm2d: 3-41                      [128, 128, 32, 32]        256\n",
       "│    │    └─ReLU: 3-42                             [128, 128, 32, 32]        --\n",
       "│    │    └─Conv2d: 3-43                           [128, 128, 32, 32]        147,584\n",
       "│    │    └─BatchNorm2d: 3-44                      [128, 128, 32, 32]        256\n",
       "│    │    └─ReLU: 3-45                             [128, 128, 32, 32]        --\n",
       "├─Sequential: 1-7                                  [128, 256, 16, 16]        --\n",
       "│    └─DynamicBasicBlock: 2-9                      [128, 256, 16, 16]        --\n",
       "│    │    └─Sequential: 3-46                       [128, 256, 16, 16]        33,280\n",
       "│    │    └─Conv2d: 3-47                           [128, 256, 16, 16]        295,168\n",
       "│    │    └─BatchNorm2d: 3-48                      [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-49                             [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-50                           [128, 256, 16, 16]        590,080\n",
       "│    │    └─BatchNorm2d: 3-51                      [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-52                             [128, 256, 16, 16]        --\n",
       "│    └─DynamicBasicBlock: 2-10                     [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-53                           [128, 256, 16, 16]        590,080\n",
       "│    │    └─BatchNorm2d: 3-54                      [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-55                             [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-56                           [128, 256, 16, 16]        590,080\n",
       "│    │    └─BatchNorm2d: 3-57                      [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-58                             [128, 256, 16, 16]        --\n",
       "│    └─DynamicBasicBlock: 2-11                     [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-59                           [128, 256, 16, 16]        590,080\n",
       "│    │    └─BatchNorm2d: 3-60                      [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-61                             [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-62                           [128, 256, 16, 16]        590,080\n",
       "│    │    └─BatchNorm2d: 3-63                      [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-64                             [128, 256, 16, 16]        --\n",
       "│    └─DynamicBasicBlock: 2-12                     [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-65                           [128, 256, 16, 16]        590,080\n",
       "│    │    └─BatchNorm2d: 3-66                      [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-67                             [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-68                           [128, 256, 16, 16]        590,080\n",
       "│    │    └─BatchNorm2d: 3-69                      [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-70                             [128, 256, 16, 16]        --\n",
       "│    └─DynamicBasicBlock: 2-13                     [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-71                           [128, 256, 16, 16]        590,080\n",
       "│    │    └─BatchNorm2d: 3-72                      [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-73                             [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-74                           [128, 256, 16, 16]        590,080\n",
       "│    │    └─BatchNorm2d: 3-75                      [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-76                             [128, 256, 16, 16]        --\n",
       "│    └─DynamicBasicBlock: 2-14                     [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-77                           [128, 256, 16, 16]        590,080\n",
       "│    │    └─BatchNorm2d: 3-78                      [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-79                             [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-80                           [128, 256, 16, 16]        590,080\n",
       "│    │    └─BatchNorm2d: 3-81                      [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-82                             [128, 256, 16, 16]        --\n",
       "├─Sequential: 1-8                                  [128, 512, 8, 8]          --\n",
       "│    └─DynamicBasicBlock: 2-15                     [128, 512, 8, 8]          --\n",
       "│    │    └─Sequential: 3-83                       [128, 512, 8, 8]          132,096\n",
       "│    │    └─Conv2d: 3-84                           [128, 512, 8, 8]          1,180,160\n",
       "│    │    └─BatchNorm2d: 3-85                      [128, 512, 8, 8]          1,024\n",
       "│    │    └─ReLU: 3-86                             [128, 512, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-87                           [128, 512, 8, 8]          2,359,808\n",
       "│    │    └─BatchNorm2d: 3-88                      [128, 512, 8, 8]          1,024\n",
       "│    │    └─ReLU: 3-89                             [128, 512, 8, 8]          --\n",
       "│    └─DynamicBasicBlock: 2-16                     [128, 512, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-90                           [128, 512, 8, 8]          2,359,808\n",
       "│    │    └─BatchNorm2d: 3-91                      [128, 512, 8, 8]          1,024\n",
       "│    │    └─ReLU: 3-92                             [128, 512, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-93                           [128, 512, 8, 8]          2,359,808\n",
       "│    │    └─BatchNorm2d: 3-94                      [128, 512, 8, 8]          1,024\n",
       "│    │    └─ReLU: 3-95                             [128, 512, 8, 8]          --\n",
       "│    └─DynamicBasicBlock: 2-17                     [128, 512, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-96                           [128, 512, 8, 8]          2,359,808\n",
       "│    │    └─BatchNorm2d: 3-97                      [128, 512, 8, 8]          1,024\n",
       "│    │    └─ReLU: 3-98                             [128, 512, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-99                           [128, 512, 8, 8]          2,359,808\n",
       "│    │    └─BatchNorm2d: 3-100                     [128, 512, 8, 8]          1,024\n",
       "│    │    └─ReLU: 3-101                            [128, 512, 8, 8]          --\n",
       "├─AdaptiveAvgPool2d: 1-9                           [128, 512, 1, 1]          --\n",
       "├─Linear: 1-10                                     [128, 50]                 25,650\n",
       "├─Softmax: 1-11                                    [128, 50]                 --\n",
       "====================================================================================================\n",
       "Total params: 21,541,047\n",
       "Trainable params: 21,541,047\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 554.45\n",
       "====================================================================================================\n",
       "Input size (MB): 8.39\n",
       "Forward/backward pass size (MB): 8388.80\n",
       "Params size (MB): 84.97\n",
       "Estimated Total Size (MB): 8482.17\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(dynamic_model1, input_size=(128, 1, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
