{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import sys\n",
    "from torchinfo import summary\n",
    "from ptflops import get_model_complexity_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 15\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "# data augmentation and normalization\n",
    "transform_train = transforms.Compose([\n",
    "                    transforms.Resize((128, 128)),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "                    transforms.Resize((128, 128)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_train1 = transforms.Compose([\n",
    "                    transforms.Resize((128, 128)),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "transform_test1 = transforms.Compose([\n",
    "                    transforms.Resize((128, 128)),\n",
    "                    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set length:63325, Validating Set length:450\n"
     ]
    }
   ],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, txt_file, img_dir, transform=None, convert=\"RGB\"):\n",
    "        self.img_labels = []\n",
    "        self.img_paths = []\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.convert = convert\n",
    "\n",
    "        with open(txt_file, 'r') as f:\n",
    "            for line in f:\n",
    "                path, label = line.strip().split(\" \")\n",
    "                self.img_paths.append(path)\n",
    "                self.img_labels.append(int(label))\n",
    "                #print(f\"{path} , {label}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_paths[idx])\n",
    "        image = Image.open(img_path).convert(self.convert)\n",
    "        label = self.img_labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "img_dir = os.getcwd() + \"/\"\n",
    "# 3 channels\n",
    "train_data_3channels = CustomImageDataset(txt_file=\"train.txt\", img_dir=img_dir, transform=transform_train, convert=\"RGB\")\n",
    "val_data_3channels = CustomImageDataset(txt_file=\"val.txt\", img_dir=img_dir, transform=transform_train, convert=\"RGB\")\n",
    "test_data_3channels = CustomImageDataset(txt_file=\"test.txt\", img_dir=img_dir, transform=transform_test, convert=\"RGB\")\n",
    "# 1 channels\n",
    "# train_data_1channels = CustomImageDataset(txt_file=\"train.txt\", img_dir=img_dir, transform=transform_train1, convert=\"L\")\n",
    "# val_data_1channels = CustomImageDataset(txt_file=\"val.txt\", img_dir=img_dir, transform=transform_train1, convert=\"L\")\n",
    "# test_data_1channels = CustomImageDataset(txt_file=\"test.txt\", img_dir=img_dir, transform=transform_test1, convert=\"L\")\n",
    "# DataLoader 3 channels\n",
    "train_loader_3channels = DataLoader(dataset=train_data_3channels, batch_size=batch_size, shuffle=True)\n",
    "val_loader_3channels = DataLoader(dataset=val_data_3channels, batch_size=batch_size, shuffle=False)\n",
    "test_loader_3channels = DataLoader(dataset=test_data_3channels, batch_size=batch_size, shuffle=False)\n",
    "# DataLoader 1 channels\n",
    "# train_loader_1channels = DataLoader(dataset=train_data_1channels, batch_size=batch_size, shuffle=True)\n",
    "# val_loader_1channels = DataLoader(dataset=val_data_1channels, batch_size=batch_size, shuffle=False)\n",
    "# test_loader_1channels = DataLoader(dataset=test_data_1channels, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Training Set length:{len(train_data_3channels)}, Validating Set length:{len(val_data_3channels)}\")\n",
    "\n",
    "test_num = len(test_data_3channels)\n",
    "test_steps = len(test_loader_3channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FourLayerModel(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super(FourLayerModel, self,).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.conv = nn.Sequential(\n",
    "            # layer 1\n",
    "            nn.Conv2d(self.in_channels, 64, (8, 8), (3, 3), (2, 2)),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d((3, 3), (1, 1)),\n",
    "\n",
    "            # layer 2\n",
    "            nn.Conv2d(64, 192, (5, 5), (1, 1), (2, 2)),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d((3, 3), (1, 1)),\n",
    "\n",
    "            # layer 3\n",
    "            nn.Conv2d(192, 384, (3, 3), (1, 1), (1, 1)),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "        )\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        # 创建一个临时的输入张量\n",
    "        with torch.no_grad():\n",
    "            temp_input = torch.zeros(1, self.in_channels, 128, 128)\n",
    "            temp_output = self.conv(temp_input)\n",
    "            self.conv_output_size = temp_output.numel()\n",
    "\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.conv_output_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 50),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv(x)\n",
    "        x = self.linear(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, epochs, learning_rate, device, model_name):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=1e-05)\n",
    "\n",
    "    loss = []\n",
    "    train_error=[]\n",
    "    val_error = []\n",
    "    valdation_error = []\n",
    "    train_loss = []\n",
    "    valdation_loss = []\n",
    "    train_accuraacy = []\n",
    "    valdation_accuracy= []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        valid_acc = 0.0\n",
    "        correct = 0.\n",
    "        total = 0.\n",
    "        V_correct = 0.\n",
    "        V_total = 0.\n",
    "        max_val_acc = 0.0\n",
    "\n",
    "        model.train()\n",
    "        train_bar = tqdm(train_loader, file=sys.stdout)\n",
    "        for step, data in enumerate(train_bar):\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits= model(images)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "            pred = logits.data.max(1, keepdim=True)[1]\n",
    "            #print(pred)\n",
    "            correct += np.sum(np.squeeze(pred.eq(labels.data.view_as(pred))).cpu().numpy())\n",
    "            total += images.size(0)\n",
    "            train_acc =  correct/total\n",
    "            train_bar.desc = \"train epoch[{}/{}]\".format(epoch + 1, epochs)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_bar = tqdm(val_loader, file=sys.stdout)\n",
    "            for val_data in val_bar:\n",
    "                val_images, val_labels = val_data\n",
    "                val_images, val_labels = val_images.to(device), val_labels.to(device)\n",
    "                outputs= model(val_images)\n",
    "                loss = criterion(outputs, val_labels)\n",
    "                valid_loss += loss.item() * val_images.size(0)\n",
    "                pred = outputs.data.max(1, keepdim=True)[1]\n",
    "                V_correct += np.sum(np.squeeze(pred.eq(val_labels.data.view_as(pred))).cpu().numpy())\n",
    "                V_total += val_images.size(0)\n",
    "                val_bar.desc = \"valid epoch[{}/{}]\".format(epoch + 1, epochs)\n",
    "\n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        train_error.append(train_loss)\n",
    "        valid_loss = valid_loss / len(val_loader.dataset)\n",
    "        val_error.append(valid_loss)\n",
    "        train_accuraacy.append( correct / total)\n",
    "        valdation_accuracy.append(V_correct / V_total)\n",
    "        if (V_correct / V_total) > max_val_acc:\n",
    "            max_val_acc = V_correct / V_total\n",
    "            torch.save(model.state_dict(), \"./models/\" + model_name + \".pth\")\n",
    "\n",
    "        print('\\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(train_loss, valid_loss))\n",
    "        print('\\tTrain Accuracy: %.3fd%% (%2d/%2d)\\tValdation Accuracy: %.3fd%% (%2d/%2d) '% (100. * correct / total, correct, total, 100. * V_correct / V_total, V_correct, V_total))\n",
    "\n",
    "    print('Finished Training') \n",
    "\n",
    "\n",
    "def test(model, test_loader ,device, type=None):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    acc = 0.0\n",
    "    test_loss = 0.0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_bar = tqdm(test_loader, file=sys.stdout)\n",
    "        for test_data in test_bar:\n",
    "            test_images, test_labels = test_data\n",
    "            test_images, test_labels = test_images.to(device), test_labels.to(device)\n",
    "            \n",
    "            outputs= model(test_images)\n",
    "            loss = criterion(outputs, test_labels)\n",
    "\n",
    "            predict_y = torch.max(outputs, dim=1)[1]\n",
    "            acc += torch.eq(predict_y, test_labels.to(device)).sum().item()\n",
    "            test_loss += loss.item()\n",
    "            test_bar.desc = \"test\"\n",
    "\n",
    "    test_accurate = acc / test_num\n",
    "    print('test_loss: %.3f  test_accuracy: %.3f' %(test_loss / test_steps, test_accurate * 100))\n",
    "    return test_loss / test_steps, test_accurate * 100.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Channels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch[1/10]: 100%|██████████| 495/495 [02:07<00:00,  3.90it/s]\n",
      "valid epoch[1/10]: 100%|██████████| 4/4 [00:00<00:00,  5.86it/s]\n",
      "\tTraining Loss: 3.911632 \tValidation Loss: 3.911017\n",
      "\tTrain Accuracy: 2.493d% (1579/63325)\tValdation Accuracy: 2.222d% (10/450) \n",
      "train epoch[2/10]: 100%|██████████| 495/495 [02:05<00:00,  3.95it/s]\n",
      "valid epoch[2/10]: 100%|██████████| 4/4 [00:00<00:00,  5.83it/s]\n",
      "\tTraining Loss: 3.906503 \tValidation Loss: 3.901314\n",
      "\tTrain Accuracy: 2.814d% (1782/63325)\tValdation Accuracy: 2.889d% (13/450) \n",
      "train epoch[3/10]: 100%|██████████| 495/495 [02:02<00:00,  4.03it/s]\n",
      "valid epoch[3/10]: 100%|██████████| 4/4 [00:00<00:00,  5.94it/s]\n",
      "\tTraining Loss: 3.892344 \tValidation Loss: 3.879102\n",
      "\tTrain Accuracy: 4.745d% (3005/63325)\tValdation Accuracy: 6.667d% (30/450) \n",
      "train epoch[4/10]: 100%|██████████| 495/495 [02:04<00:00,  3.97it/s]\n",
      "valid epoch[4/10]: 100%|██████████| 4/4 [00:00<00:00,  5.79it/s]\n",
      "\tTraining Loss: 3.874203 \tValidation Loss: 3.864804\n",
      "\tTrain Accuracy: 6.885d% (4360/63325)\tValdation Accuracy: 7.556d% (34/450) \n",
      "train epoch[5/10]: 100%|██████████| 495/495 [02:02<00:00,  4.04it/s]\n",
      "valid epoch[5/10]: 100%|██████████| 4/4 [00:00<00:00,  5.98it/s]\n",
      "\tTraining Loss: 3.860306 \tValidation Loss: 3.844459\n",
      "\tTrain Accuracy: 8.423d% (5334/63325)\tValdation Accuracy: 10.222d% (46/450) \n",
      "train epoch[6/10]: 100%|██████████| 495/495 [02:01<00:00,  4.06it/s]\n",
      "valid epoch[6/10]: 100%|██████████| 4/4 [00:00<00:00,  5.98it/s]\n",
      "\tTraining Loss: 3.850628 \tValidation Loss: 3.836167\n",
      "\tTrain Accuracy: 9.525d% (6032/63325)\tValdation Accuracy: 11.556d% (52/450) \n",
      "train epoch[7/10]: 100%|██████████| 495/495 [02:02<00:00,  4.05it/s]\n",
      "valid epoch[7/10]: 100%|██████████| 4/4 [00:00<00:00,  5.94it/s]\n",
      "\tTraining Loss: 3.841181 \tValidation Loss: 3.828223\n",
      "\tTrain Accuracy: 10.465d% (6627/63325)\tValdation Accuracy: 11.333d% (51/450) \n",
      "train epoch[8/10]: 100%|██████████| 495/495 [02:02<00:00,  4.03it/s]\n",
      "valid epoch[8/10]: 100%|██████████| 4/4 [00:00<00:00,  5.99it/s]\n",
      "\tTraining Loss: 3.832882 \tValidation Loss: 3.829228\n",
      "\tTrain Accuracy: 11.370d% (7200/63325)\tValdation Accuracy: 11.111d% (50/450) \n",
      "train epoch[9/10]: 100%|██████████| 495/495 [02:02<00:00,  4.03it/s]\n",
      "valid epoch[9/10]: 100%|██████████| 4/4 [00:00<00:00,  5.95it/s]\n",
      "\tTraining Loss: 3.826737 \tValidation Loss: 3.823309\n",
      "\tTrain Accuracy: 11.951d% (7568/63325)\tValdation Accuracy: 12.000d% (54/450) \n",
      "train epoch[10/10]: 100%|██████████| 495/495 [02:02<00:00,  4.03it/s]\n",
      "valid epoch[10/10]: 100%|██████████| 4/4 [00:00<00:00,  5.89it/s]\n",
      "\tTraining Loss: 3.822453 \tValidation Loss: 3.820290\n",
      "\tTrain Accuracy: 12.415d% (7862/63325)\tValdation Accuracy: 12.000d% (54/450) \n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "model = FourLayerModel(3)\n",
    "num_epochs = 10\n",
    "lr = 0.001\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "train(model, train_loader_3channels, val_loader_3channels, epochs=num_epochs, learning_rate=lr, device=device, model_name=\"3_channels_four_layer_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: 100%|██████████| 4/4 [00:00<00:00,  5.88it/s]\n",
      "test_loss: 3.798  test_accuracy: 12.667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.7982678413391113, 12.666666666666668)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model = FourLayerModel(3)\n",
    "test_model.load_state_dict(torch.load(os.getcwd() + '/models/3_channels_four_layer_model.pth'))\n",
    "test_model.to(device)\n",
    "test_model.eval()\n",
    "test(test_model, test_loader_3channels, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch[1/15]: 100%|██████████| 495/495 [02:03<00:00,  4.01it/s]\n",
      "valid epoch[1/15]: 100%|██████████| 4/4 [00:00<00:00,  5.75it/s]\n",
      "\tTraining Loss: 3.911531 \tValidation Loss: 3.910545\n",
      "\tTrain Accuracy: 2.626d% (1663/63325)\tValdation Accuracy: 2.000d% ( 9/450) \n",
      "train epoch[2/15]: 100%|██████████| 495/495 [02:05<00:00,  3.96it/s]\n",
      "valid epoch[2/15]: 100%|██████████| 4/4 [00:00<00:00,  5.82it/s]\n",
      "\tTraining Loss: 3.903065 \tValidation Loss: 3.888396\n",
      "\tTrain Accuracy: 3.463d% (2193/63325)\tValdation Accuracy: 5.333d% (24/450) \n",
      "train epoch[3/15]: 100%|██████████| 495/495 [02:03<00:00,  4.00it/s]\n",
      "valid epoch[3/15]: 100%|██████████| 4/4 [00:00<00:00,  5.99it/s]\n",
      "\tTraining Loss: 3.884199 \tValidation Loss: 3.880554\n",
      "\tTrain Accuracy: 5.677d% (3595/63325)\tValdation Accuracy: 6.222d% (28/450) \n",
      "train epoch[4/15]: 100%|██████████| 495/495 [02:02<00:00,  4.03it/s]\n",
      "valid epoch[4/15]: 100%|██████████| 4/4 [00:00<00:00,  5.96it/s]\n",
      "\tTraining Loss: 3.876852 \tValidation Loss: 3.875721\n",
      "\tTrain Accuracy: 6.452d% (4086/63325)\tValdation Accuracy: 6.667d% (30/450) \n",
      "train epoch[5/15]: 100%|██████████| 495/495 [02:04<00:00,  3.97it/s]\n",
      "valid epoch[5/15]: 100%|██████████| 4/4 [00:00<00:00,  5.83it/s]\n",
      "\tTraining Loss: 3.870089 \tValidation Loss: 3.861456\n",
      "\tTrain Accuracy: 7.330d% (4642/63325)\tValdation Accuracy: 9.333d% (42/450) \n",
      "train epoch[6/15]: 100%|██████████| 495/495 [02:03<00:00,  3.99it/s]\n",
      "valid epoch[6/15]: 100%|██████████| 4/4 [00:00<00:00,  5.97it/s]\n",
      "\tTraining Loss: 3.859686 \tValidation Loss: 3.840132\n",
      "\tTrain Accuracy: 8.557d% (5419/63325)\tValdation Accuracy: 11.556d% (52/450) \n",
      "train epoch[7/15]: 100%|██████████| 495/495 [02:03<00:00,  4.00it/s]\n",
      "valid epoch[7/15]: 100%|██████████| 4/4 [00:00<00:00,  5.94it/s]\n",
      "\tTraining Loss: 3.848166 \tValidation Loss: 3.831707\n",
      "\tTrain Accuracy: 9.826d% (6222/63325)\tValdation Accuracy: 11.333d% (51/450) \n",
      "train epoch[8/15]: 100%|██████████| 495/495 [02:04<00:00,  3.99it/s]\n",
      "valid epoch[8/15]: 100%|██████████| 4/4 [00:00<00:00,  5.88it/s]\n",
      "\tTraining Loss: 3.841876 \tValidation Loss: 3.822432\n",
      "\tTrain Accuracy: 10.411d% (6593/63325)\tValdation Accuracy: 12.889d% (58/450) \n",
      "train epoch[9/15]: 100%|██████████| 495/495 [02:04<00:00,  3.97it/s]\n",
      "valid epoch[9/15]: 100%|██████████| 4/4 [00:00<00:00,  5.98it/s]\n",
      "\tTraining Loss: 3.835650 \tValidation Loss: 3.823294\n",
      "\tTrain Accuracy: 10.985d% (6956/63325)\tValdation Accuracy: 12.667d% (57/450) \n",
      "train epoch[10/15]: 100%|██████████| 495/495 [02:03<00:00,  4.01it/s]\n",
      "valid epoch[10/15]: 100%|██████████| 4/4 [00:00<00:00,  5.97it/s]\n",
      "\tTraining Loss: 3.831880 \tValidation Loss: 3.818740\n",
      "\tTrain Accuracy: 11.406d% (7223/63325)\tValdation Accuracy: 13.556d% (61/450) \n",
      "train epoch[11/15]: 100%|██████████| 495/495 [02:04<00:00,  3.98it/s]\n",
      "valid epoch[11/15]: 100%|██████████| 4/4 [00:00<00:00,  5.93it/s]\n",
      "\tTraining Loss: 3.829681 \tValidation Loss: 3.814084\n",
      "\tTrain Accuracy: 11.607d% (7350/63325)\tValdation Accuracy: 13.111d% (59/450) \n",
      "train epoch[12/15]: 100%|██████████| 495/495 [02:04<00:00,  3.98it/s]\n",
      "valid epoch[12/15]: 100%|██████████| 4/4 [00:00<00:00,  5.96it/s]\n",
      "\tTraining Loss: 3.826599 \tValidation Loss: 3.809541\n",
      "\tTrain Accuracy: 11.927d% (7553/63325)\tValdation Accuracy: 14.444d% (65/450) \n",
      "train epoch[13/15]: 100%|██████████| 495/495 [02:03<00:00,  4.00it/s]\n",
      "valid epoch[13/15]: 100%|██████████| 4/4 [00:00<00:00,  5.94it/s]\n",
      "\tTraining Loss: 3.823497 \tValidation Loss: 3.809152\n",
      "\tTrain Accuracy: 12.163d% (7702/63325)\tValdation Accuracy: 14.222d% (64/450) \n",
      "train epoch[14/15]: 100%|██████████| 495/495 [02:03<00:00,  3.99it/s]\n",
      "valid epoch[14/15]: 100%|██████████| 4/4 [00:00<00:00,  6.00it/s]\n",
      "\tTraining Loss: 3.821620 \tValidation Loss: 3.812032\n",
      "\tTrain Accuracy: 12.352d% (7822/63325)\tValdation Accuracy: 13.111d% (59/450) \n",
      "train epoch[15/15]: 100%|██████████| 495/495 [02:04<00:00,  3.99it/s]\n",
      "valid epoch[15/15]: 100%|██████████| 4/4 [00:00<00:00,  5.91it/s]\n",
      "\tTraining Loss: 3.819447 \tValidation Loss: 3.811168\n",
      "\tTrain Accuracy: 12.565d% (7957/63325)\tValdation Accuracy: 13.778d% (62/450) \n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "model1 = FourLayerModel(3)\n",
    "num_epochs = 15\n",
    "lr = 0.001\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model1.to(device)\n",
    "train(model1, train_loader_3channels, val_loader_3channels, epochs=num_epochs, learning_rate=lr, device=device, model_name=\"3_channels_four_layer_model1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: 100%|██████████| 4/4 [00:00<00:00,  5.97it/s]\n",
      "test_loss: 3.796  test_accuracy: 12.889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.796234905719757, 12.88888888888889)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model = FourLayerModel(3)\n",
    "test_model.load_state_dict(torch.load(os.getcwd() + '/models/3_channels_four_layer_model1.pth'))\n",
    "test_model.to(device)\n",
    "test_model.eval()\n",
    "test(test_model, test_loader_3channels, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch[1/20]: 100%|██████████| 495/495 [02:04<00:00,  3.97it/s]\n",
      "valid epoch[1/20]: 100%|██████████| 4/4 [00:00<00:00,  5.91it/s]\n",
      "\tTraining Loss: 3.911024 \tValidation Loss: 3.909868\n",
      "\tTrain Accuracy: 2.099d% (1329/63325)\tValdation Accuracy: 2.000d% ( 9/450) \n",
      "train epoch[2/20]: 100%|██████████| 495/495 [02:02<00:00,  4.04it/s]\n",
      "valid epoch[2/20]: 100%|██████████| 4/4 [00:00<00:00,  5.81it/s]\n",
      "\tTraining Loss: 3.901221 \tValidation Loss: 3.888909\n",
      "\tTrain Accuracy: 3.714d% (2352/63325)\tValdation Accuracy: 5.333d% (24/450) \n",
      "train epoch[3/20]: 100%|██████████| 495/495 [02:02<00:00,  4.04it/s]\n",
      "valid epoch[3/20]: 100%|██████████| 4/4 [00:00<00:00,  5.91it/s]\n",
      "\tTraining Loss: 3.882996 \tValidation Loss: 3.873598\n",
      "\tTrain Accuracy: 5.878d% (3722/63325)\tValdation Accuracy: 7.111d% (32/450) \n",
      "train epoch[4/20]: 100%|██████████| 495/495 [02:02<00:00,  4.03it/s]\n",
      "valid epoch[4/20]: 100%|██████████| 4/4 [00:00<00:00,  5.86it/s]\n",
      "\tTraining Loss: 3.869102 \tValidation Loss: 3.859172\n",
      "\tTrain Accuracy: 7.447d% (4716/63325)\tValdation Accuracy: 8.222d% (37/450) \n",
      "train epoch[5/20]: 100%|██████████| 495/495 [02:02<00:00,  4.03it/s]\n",
      "valid epoch[5/20]: 100%|██████████| 4/4 [00:00<00:00,  5.86it/s]\n",
      "\tTraining Loss: 3.856630 \tValidation Loss: 3.854645\n",
      "\tTrain Accuracy: 8.720d% (5522/63325)\tValdation Accuracy: 8.667d% (39/450) \n",
      "train epoch[6/20]: 100%|██████████| 495/495 [02:03<00:00,  4.02it/s]\n",
      "valid epoch[6/20]: 100%|██████████| 4/4 [00:00<00:00,  5.93it/s]\n",
      "\tTraining Loss: 3.846867 \tValidation Loss: 3.852640\n",
      "\tTrain Accuracy: 9.835d% (6228/63325)\tValdation Accuracy: 8.444d% (38/450) \n",
      "train epoch[7/20]: 100%|██████████| 495/495 [02:03<00:00,  3.99it/s]\n",
      "valid epoch[7/20]: 100%|██████████| 4/4 [00:00<00:00,  5.93it/s]\n",
      "\tTraining Loss: 3.837543 \tValidation Loss: 3.837390\n",
      "\tTrain Accuracy: 10.828d% (6857/63325)\tValdation Accuracy: 10.889d% (49/450) \n",
      "train epoch[8/20]: 100%|██████████| 495/495 [02:04<00:00,  3.98it/s]\n",
      "valid epoch[8/20]: 100%|██████████| 4/4 [00:00<00:00,  5.76it/s]\n",
      "\tTraining Loss: 3.829271 \tValidation Loss: 3.820707\n",
      "\tTrain Accuracy: 11.779d% (7459/63325)\tValdation Accuracy: 12.889d% (58/450) \n",
      "train epoch[9/20]: 100%|██████████| 495/495 [02:05<00:00,  3.93it/s]\n",
      "valid epoch[9/20]: 100%|██████████| 4/4 [00:00<00:00,  5.75it/s]\n",
      "\tTraining Loss: 3.822315 \tValidation Loss: 3.822383\n",
      "\tTrain Accuracy: 12.474d% (7899/63325)\tValdation Accuracy: 13.111d% (59/450) \n",
      "train epoch[10/20]: 100%|██████████| 495/495 [02:04<00:00,  3.97it/s]\n",
      "valid epoch[10/20]: 100%|██████████| 4/4 [00:00<00:00,  5.96it/s]\n",
      "\tTraining Loss: 3.817819 \tValidation Loss: 3.808020\n",
      "\tTrain Accuracy: 12.835d% (8128/63325)\tValdation Accuracy: 14.889d% (67/450) \n",
      "train epoch[11/20]: 100%|██████████| 495/495 [02:04<00:00,  3.97it/s]\n",
      "valid epoch[11/20]: 100%|██████████| 4/4 [00:00<00:00,  5.84it/s]\n",
      "\tTraining Loss: 3.813749 \tValidation Loss: 3.810438\n",
      "\tTrain Accuracy: 13.197d% (8357/63325)\tValdation Accuracy: 13.556d% (61/450) \n",
      "train epoch[12/20]: 100%|██████████| 495/495 [02:04<00:00,  3.99it/s]\n",
      "valid epoch[12/20]: 100%|██████████| 4/4 [00:00<00:00,  5.96it/s]\n",
      "\tTraining Loss: 3.809340 \tValidation Loss: 3.807817\n",
      "\tTrain Accuracy: 13.705d% (8679/63325)\tValdation Accuracy: 13.556d% (61/450) \n",
      "train epoch[13/20]: 100%|██████████| 495/495 [02:04<00:00,  3.98it/s]\n",
      "valid epoch[13/20]: 100%|██████████| 4/4 [00:00<00:00,  5.94it/s]\n",
      "\tTraining Loss: 3.801527 \tValidation Loss: 3.794181\n",
      "\tTrain Accuracy: 14.547d% (9212/63325)\tValdation Accuracy: 15.333d% (69/450) \n",
      "train epoch[14/20]: 100%|██████████| 495/495 [02:05<00:00,  3.96it/s]\n",
      "valid epoch[14/20]: 100%|██████████| 4/4 [00:00<00:00,  5.72it/s]\n",
      "\tTraining Loss: 3.795655 \tValidation Loss: 3.795423\n",
      "\tTrain Accuracy: 15.147d% (9592/63325)\tValdation Accuracy: 15.556d% (70/450) \n",
      "train epoch[15/20]: 100%|██████████| 495/495 [02:05<00:00,  3.96it/s]\n",
      "valid epoch[15/20]: 100%|██████████| 4/4 [00:00<00:00,  5.75it/s]\n",
      "\tTraining Loss: 3.791852 \tValidation Loss: 3.804939\n",
      "\tTrain Accuracy: 15.552d% (9848/63325)\tValdation Accuracy: 14.000d% (63/450) \n",
      "train epoch[16/20]: 100%|██████████| 495/495 [02:05<00:00,  3.95it/s]\n",
      "valid epoch[16/20]: 100%|██████████| 4/4 [00:00<00:00,  5.74it/s]\n",
      "\tTraining Loss: 3.789197 \tValidation Loss: 3.799460\n",
      "\tTrain Accuracy: 15.725d% (9958/63325)\tValdation Accuracy: 14.667d% (66/450) \n",
      "train epoch[17/20]: 100%|██████████| 495/495 [02:04<00:00,  3.98it/s]\n",
      "valid epoch[17/20]: 100%|██████████| 4/4 [00:00<00:00,  5.78it/s]\n",
      "\tTraining Loss: 3.784478 \tValidation Loss: 3.786794\n",
      "\tTrain Accuracy: 16.197d% (10257/63325)\tValdation Accuracy: 16.667d% (75/450) \n",
      "train epoch[18/20]: 100%|██████████| 495/495 [02:06<00:00,  3.93it/s]\n",
      "valid epoch[18/20]: 100%|██████████| 4/4 [00:00<00:00,  5.82it/s]\n",
      "\tTraining Loss: 3.782444 \tValidation Loss: 3.784443\n",
      "\tTrain Accuracy: 16.469d% (10429/63325)\tValdation Accuracy: 16.444d% (74/450) \n",
      "train epoch[19/20]: 100%|██████████| 495/495 [02:05<00:00,  3.93it/s]\n",
      "valid epoch[19/20]: 100%|██████████| 4/4 [00:00<00:00,  5.82it/s]\n",
      "\tTraining Loss: 3.779802 \tValidation Loss: 3.784538\n",
      "\tTrain Accuracy: 16.711d% (10582/63325)\tValdation Accuracy: 16.222d% (73/450) \n",
      "train epoch[20/20]: 100%|██████████| 495/495 [02:05<00:00,  3.94it/s]\n",
      "valid epoch[20/20]: 100%|██████████| 4/4 [00:00<00:00,  5.85it/s]\n",
      "\tTraining Loss: 3.776579 \tValidation Loss: 3.771204\n",
      "\tTrain Accuracy: 17.038d% (10789/63325)\tValdation Accuracy: 17.556d% (79/450) \n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "model2 = FourLayerModel(3)\n",
    "num_epochs = 20\n",
    "lr = 0.001\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model2.to(device)\n",
    "train(model2, train_loader_3channels, val_loader_3channels, epochs=num_epochs, learning_rate=lr, device=device, model_name=\"3_channels_four_layer_model2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: 100%|██████████| 4/4 [00:00<00:00,  6.08it/s]\n",
      "test_loss: 3.745  test_accuracy: 17.556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.7451440691947937, 17.555555555555554)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model = FourLayerModel(3)\n",
    "test_model.load_state_dict(torch.load(os.getcwd() + '/models/3_channels_four_layer_model2.pth'))\n",
    "test_model.to(device)\n",
    "test_model.eval()\n",
    "test(test_model, test_loader_3channels, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "FourLayerModel                           [128, 50]                 --\n",
       "├─Sequential: 1-1                        [128, 384, 38, 38]        --\n",
       "│    └─Conv2d: 2-1                       [128, 64, 42, 42]         12,352\n",
       "│    └─ReLU: 2-2                         [128, 64, 42, 42]         --\n",
       "│    └─MaxPool2d: 2-3                    [128, 64, 40, 40]         --\n",
       "│    └─Conv2d: 2-4                       [128, 192, 40, 40]        307,392\n",
       "│    └─ReLU: 2-5                         [128, 192, 40, 40]        --\n",
       "│    └─MaxPool2d: 2-6                    [128, 192, 38, 38]        --\n",
       "│    └─Conv2d: 2-7                       [128, 384, 38, 38]        663,936\n",
       "│    └─ReLU: 2-8                         [128, 384, 38, 38]        --\n",
       "│    └─Dropout: 2-9                      [128, 384, 38, 38]        --\n",
       "├─Sequential: 1-2                        [128, 50]                 --\n",
       "│    └─Flatten: 2-10                     [128, 554496]             --\n",
       "│    └─Linear: 2-11                      [128, 512]                283,902,464\n",
       "│    └─ReLU: 2-12                        [128, 512]                --\n",
       "│    └─Dropout: 2-13                     [128, 512]                --\n",
       "│    └─Linear: 2-14                      [128, 50]                 25,650\n",
       "│    └─Softmax: 2-15                     [128, 50]                 --\n",
       "==========================================================================================\n",
       "Total params: 284,911,794\n",
       "Trainable params: 284,911,794\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 224.80\n",
       "==========================================================================================\n",
       "Input size (MB): 25.17\n",
       "Forward/backward pass size (MB): 998.56\n",
       "Params size (MB): 1139.65\n",
       "Estimated Total Size (MB): 2163.37\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model2, input_size=(128, 3, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
